2023-11-05 16:31:12,530 - root - INFO - i am in main method...
2023-11-05 16:31:12,530 - root - ERROR - An error occurred when calling main(). Please check the trace...
2023-11-05 16:34:16,339 - root - INFO - i am in main method...
2023-11-05 16:34:45,533 - root - INFO - Validating spark object
2023-11-05 16:44:18,155 - root - INFO - i am in main method...
2023-11-05 16:44:18,155 - Create_spark - INFO - get_spark_object method started...
2023-11-05 16:44:18,155 - Create_spark - INFO - master is local[*]
2023-11-05 16:44:27,557 - root - INFO - Validating spark object.......
2023-11-05 16:44:27,557 - Validate - WARNING - Started get_current_date method ...
2023-11-05 16:44:30,401 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 16:44:30,402 - Validate - WARNING - Validation done... go ahead
2023-11-05 16:48:00,926 - root - INFO - i am in main method...
2023-11-05 16:48:00,926 - Create_spark - INFO - get_spark_object method started...
2023-11-05 16:48:00,926 - Create_spark - INFO - master is local[*]
2023-11-05 16:48:12,321 - root - INFO - Validating spark object.......
2023-11-05 16:48:12,321 - Validate - WARNING - Started get_current_date method ...
2023-11-05 16:48:18,379 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 16:48:18,379 - Validate - WARNING - Validation done... go ahead
2023-11-05 16:48:18,379 - root - INFO - Application done...
2023-11-05 16:53:54,222 - root - INFO - i am in main method...
2023-11-05 16:53:54,223 - Create_spark - INFO - get_spark_object method started...
2023-11-05 16:53:54,223 - Create_spark - INFO - master is local[*]
2023-11-05 16:54:05,537 - root - INFO - Validating spark object.......
2023-11-05 16:54:05,537 - Validate - WARNING - Started get_current_date method ...
2023-11-05 16:54:10,729 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 16:54:10,729 - Validate - WARNING - Validation done... go ahead
2023-11-05 16:54:10,729 - root - INFO - reading file which is of parquet
2023-11-05 16:54:10,729 - root - INFO - Application done...
2023-11-05 17:06:23,649 - root - INFO - i am in main method...
2023-11-05 17:06:23,650 - Create_spark - INFO - get_spark_object method started...
2023-11-05 17:06:23,650 - Create_spark - INFO - master is local[*]
2023-11-05 17:06:32,479 - root - INFO - Validating spark object.......
2023-11-05 17:06:32,479 - Validate - WARNING - Started get_current_date method ...
2023-11-05 17:06:35,128 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:06:35,128 - Validate - WARNING - Validation done... go ahead
2023-11-05 17:06:35,129 - root - INFO - reading file which is of parquet
2023-11-05 17:11:48,613 - root - INFO - i am in main method...
2023-11-05 17:11:48,613 - Create_spark - INFO - get_spark_object method started...
2023-11-05 17:11:48,613 - Create_spark - INFO - master is local[*]
2023-11-05 17:11:58,109 - root - INFO - Validating spark object.......
2023-11-05 17:11:58,109 - Validate - WARNING - Started get_current_date method ...
2023-11-05 17:12:04,239 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:12:04,239 - Validate - WARNING - Validation done... go ahead
2023-11-05 17:12:04,239 - root - INFO - reading file which is of parquet
2023-11-05 17:12:04,240 - Ingest - WARNING - load files method started....
2023-11-05 17:12:05,869 - Ingest - WARNING - dataframe created successfully....
2023-11-05 17:12:05,891 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-11-05 17:12:07,820 - root - INFO - validating the dataframe...
2023-11-05 17:12:07,820 - Ingest - WARNING - here to count the records in the  df_city
2023-11-05 17:12:08,664 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are : 28338
2023-11-05 17:12:08,664 - root - INFO - Application done...
2023-11-05 17:17:26,583 - root - INFO - i am in main method...
2023-11-05 17:17:26,583 - Create_spark - INFO - get_spark_object method started...
2023-11-05 17:17:26,584 - Create_spark - INFO - master is local[*]
2023-11-05 17:17:36,419 - root - INFO - Validating spark object.......
2023-11-05 17:17:36,419 - Validate - WARNING - Started get_current_date method ...
2023-11-05 17:17:39,760 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:17:39,760 - Validate - WARNING - Validation done... go ahead
2023-11-05 17:17:39,761 - root - INFO - reading file which is of csv
2023-11-05 17:17:39,761 - Ingest - WARNING - load files method started....
2023-11-05 17:18:21,111 - root - INFO - i am in main method...
2023-11-05 17:18:21,111 - Create_spark - INFO - get_spark_object method started...
2023-11-05 17:18:21,111 - Create_spark - INFO - master is local[*]
2023-11-05 17:18:30,188 - root - INFO - Validating spark object.......
2023-11-05 17:18:30,188 - Validate - WARNING - Started get_current_date method ...
2023-11-05 17:18:32,966 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:18:32,966 - Validate - WARNING - Validation done... go ahead
2023-11-05 17:18:32,966 - root - INFO - reading file which is of parquet
2023-11-05 17:18:32,966 - Ingest - WARNING - load files method started....
2023-11-05 17:18:33,551 - Ingest - WARNING - dataframe created successfully....
2023-11-05 17:18:33,561 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-11-05 17:18:34,373 - root - INFO - validating the dataframe...
2023-11-05 17:18:34,373 - Ingest - WARNING - here to count the records in the  df_city
2023-11-05 17:18:34,739 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are : 28338
2023-11-05 17:18:34,739 - Ingest - WARNING - load files method started....
2023-11-05 17:20:21,286 - root - INFO - i am in main method...
2023-11-05 17:20:21,286 - Create_spark - INFO - get_spark_object method started...
2023-11-05 17:20:21,286 - Create_spark - INFO - master is local[*]
2023-11-05 17:20:30,149 - root - INFO - Validating spark object.......
2023-11-05 17:20:30,149 - Validate - WARNING - Started get_current_date method ...
2023-11-05 17:20:33,006 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:20:33,006 - Validate - WARNING - Validation done... go ahead
2023-11-05 17:20:33,006 - root - INFO - reading file which is of parquet
2023-11-05 17:20:33,006 - Ingest - WARNING - load files method started....
2023-11-05 17:20:33,609 - Ingest - WARNING - dataframe created successfully....
2023-11-05 17:20:33,617 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-11-05 17:20:34,442 - root - INFO - validating the dataframe...
2023-11-05 17:20:34,442 - Ingest - WARNING - here to count the records in the  df_city
2023-11-05 17:20:34,858 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are : 28338
2023-11-05 17:20:34,858 - root - INFO - reading file which is of csv
2023-11-05 17:20:34,859 - Ingest - WARNING - load files method started....
2023-11-05 17:22:38,615 - root - INFO - i am in main method...
2023-11-05 17:22:38,615 - Create_spark - INFO - get_spark_object method started...
2023-11-05 17:22:38,615 - Create_spark - INFO - master is local[*]
2023-11-05 17:22:48,127 - root - INFO - Validating spark object.......
2023-11-05 17:22:48,127 - Validate - WARNING - Started get_current_date method ...
2023-11-05 17:22:54,076 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:22:54,076 - Validate - WARNING - Validation done... go ahead
2023-11-05 17:22:54,076 - root - INFO - reading file which is of parquet
2023-11-05 17:22:54,076 - Ingest - WARNING - load files method started....
2023-11-05 17:22:55,398 - Ingest - WARNING - dataframe created successfully....
2023-11-05 17:22:55,424 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-11-05 17:22:57,073 - root - INFO - validating the dataframe...
2023-11-05 17:22:57,073 - Ingest - WARNING - here to count the records in the  df_city
2023-11-05 17:22:57,806 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are : 28338
2023-11-05 17:22:57,806 - root - INFO - reading file which is of csv
2023-11-05 17:22:57,807 - Ingest - WARNING - load files method started....
2023-11-05 17:27:25,140 - root - INFO - i am in main method...
2023-11-05 17:27:25,140 - Create_spark - INFO - get_spark_object method started...
2023-11-05 17:27:25,140 - Create_spark - INFO - master is local[*]
2023-11-05 17:27:33,996 - root - INFO - Validating spark object.......
2023-11-05 17:27:33,996 - Validate - WARNING - Started get_current_date method ...
2023-11-05 17:27:36,805 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:27:36,805 - Validate - WARNING - Validation done... go ahead
2023-11-05 17:27:36,805 - root - INFO - reading file which is of parquet
2023-11-05 17:27:36,805 - Ingest - WARNING - load files method started....
2023-11-05 17:27:37,501 - Ingest - WARNING - dataframe created successfully....
2023-11-05 17:27:37,510 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-11-05 17:27:38,425 - root - INFO - validating the dataframe...
2023-11-05 17:27:38,425 - Ingest - WARNING - here to count the records in the  df_city
2023-11-05 17:27:38,813 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are : 28338
2023-11-05 17:27:38,813 - root - INFO - reading file which is of csv
2023-11-05 17:27:38,813 - Ingest - WARNING - load files method started....
2023-11-05 17:31:14,348 - root - INFO - i am in main method...
2023-11-05 17:31:14,348 - Create_spark - INFO - get_spark_object method started...
2023-11-05 17:31:14,348 - Create_spark - INFO - master is local[*]
2023-11-05 17:31:22,995 - root - INFO - Validating spark object.......
2023-11-05 17:31:22,995 - Validate - WARNING - Started get_current_date method ...
2023-11-05 17:31:25,778 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:31:25,778 - Validate - WARNING - Validation done... go ahead
2023-11-05 17:31:25,778 - root - INFO - reading file which is of parquet
2023-11-05 17:31:25,778 - Ingest - WARNING - load files method started....
2023-11-05 17:31:26,355 - Ingest - WARNING - dataframe created successfully....
2023-11-05 17:31:26,364 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-11-05 17:31:27,319 - root - INFO - validating the dataframe...
2023-11-05 17:31:27,319 - Ingest - WARNING - here to count the records in the  df_city
2023-11-05 17:31:27,678 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are : 28338
2023-11-05 17:31:27,678 - root - INFO - reading file which is of csv
2023-11-05 17:31:27,679 - Ingest - WARNING - load files method started....
2023-11-05 17:32:43,273 - root - INFO - i am in main method...
2023-11-05 17:32:43,273 - Create_spark - INFO - get_spark_object method started...
2023-11-05 17:32:43,273 - Create_spark - INFO - master is local[*]
2023-11-05 17:32:52,629 - root - INFO - Validating spark object.......
2023-11-05 17:32:52,630 - Validate - WARNING - Started get_current_date method ...
2023-11-05 17:32:57,221 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:32:57,221 - Validate - WARNING - Validation done... go ahead
2023-11-05 17:32:57,221 - root - INFO - reading file which is of parquet
2023-11-05 17:32:57,221 - Ingest - WARNING - load files method started....
2023-11-05 17:32:58,490 - Ingest - WARNING - dataframe created successfully....
2023-11-05 17:32:58,508 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-11-05 17:33:00,240 - root - INFO - validating the dataframe...
2023-11-05 17:33:00,240 - Ingest - WARNING - here to count the records in the  df_city
2023-11-05 17:33:01,016 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are : 28338
2023-11-05 17:33:01,017 - root - INFO - reading file which is of csv
2023-11-05 17:33:01,017 - Ingest - WARNING - load files method started....
2023-11-05 17:35:33,198 - root - INFO - i am in main method...
2023-11-05 17:35:33,198 - Create_spark - INFO - get_spark_object method started...
2023-11-05 17:35:33,198 - Create_spark - INFO - master is local[*]
2023-11-05 17:35:52,859 - root - INFO - Validating spark object.......
2023-11-05 17:35:52,859 - Validate - WARNING - Started get_current_date method ...
2023-11-05 17:35:55,485 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:35:55,485 - Validate - WARNING - Validation done... go ahead
2023-11-05 17:35:55,485 - root - INFO - reading file which is of parquet
2023-11-05 17:35:55,485 - Ingest - WARNING - load files method started....
2023-11-05 17:35:56,083 - Ingest - WARNING - dataframe created successfully....
2023-11-05 17:35:56,092 - root - INFO - displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-11-05 17:35:56,902 - root - INFO - validating the dataframe...
2023-11-05 17:35:56,902 - Ingest - WARNING - here to count the records in the  df_city
2023-11-05 17:35:57,240 - Ingest - WARNING - Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are : 28338
2023-11-05 17:35:57,240 - root - INFO - reading file which is of csv
2023-11-05 17:35:57,240 - Ingest - WARNING - load files method started....
2023-11-05 17:50:31,304 - root - INFO - i am in main method...
2023-11-05 17:50:31,304 - Create_spark - INFO - get_spark_object method started...
2023-11-05 17:50:31,304 - Create_spark - INFO - master is local[*]
2023-11-05 17:50:39,901 - root - INFO - Validating spark object.......
2023-11-05 17:50:39,901 - Validate - WARNING - Started get_current_date method ...
2023-11-05 17:50:42,545 - Validate - WARNING - validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:50:42,545 - Validate - WARNING - Validation done... go ahead
2023-11-05 17:50:42,545 - root - INFO - reading file which is of > parquet
2023-11-05 17:53:33,612 - root -INFO -i am in main method...
2023-11-05 17:53:33,612 - Create_spark -INFO -get_spark_object method started...
2023-11-05 17:53:33,612 - Create_spark -INFO -master is local[*]
2023-11-05 17:53:42,230 - root -INFO -Validating spark object.......
2023-11-05 17:53:42,230 - Validate -WARNING -Started get_current_date method ...
2023-11-05 17:53:44,836 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 17:53:44,836 - Validate -WARNING -Validation done... go ahead
2023-11-05 17:53:44,836 - root -INFO -reading file which is of > parquet
2023-11-05 17:53:44,836 - Ingest -WARNING -load_files method started
2023-11-05 17:53:45,437 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 17:53:45,437 - root -INFO -displaying file
2023-11-05 17:53:46,256 - root -INFO -here to validate the df
2023-11-05 17:53:46,256 - Ingest -WARNING -here to count the records in the df_city
2023-11-05 17:53:46,633 - Ingest -WARNING -number of records 28338 :: 
2023-11-05 17:53:46,633 - root -INFO -checking for the files in the Fact...
2023-11-05 17:53:46,634 - root -INFO -reading file which is of > csv
2023-11-05 17:53:46,634 - Ingest -WARNING -load_files method started
2023-11-05 17:53:50,972 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 17:53:50,972 - root -INFO -displaying the df_fact dataframe
2023-11-05 17:53:51,242 - Ingest -WARNING -here to count the records in the df_fact
2023-11-05 17:53:51,933 - Ingest -WARNING -number of records 1329329 :: 
2023-11-05 17:53:51,933 - root -INFO -Application done...
2023-11-05 18:17:30,907 - root -INFO -i am in main method...
2023-11-05 18:17:30,908 - Create_spark -INFO -get_spark_object method started...
2023-11-05 18:17:30,908 - Create_spark -INFO -master is local[*]
2023-11-05 18:17:41,622 - root -INFO -Validating spark object.......
2023-11-05 18:17:41,622 - Validate -WARNING -Started get_current_date method ...
2023-11-05 18:17:47,625 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 18:17:47,626 - Validate -WARNING -Validation done... go ahead
2023-11-05 18:17:47,626 - root -INFO -reading file which is of > parquet
2023-11-05 18:17:47,626 - Ingest -WARNING -load_files method started
2023-11-05 18:17:49,042 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 18:17:49,042 - root -INFO -displaying file
2023-11-05 18:17:49,042 - root -INFO -here to validate the df
2023-11-05 18:17:49,043 - Ingest -WARNING -here to count the records in the df_city
2023-11-05 18:17:50,227 - Ingest -WARNING -number of records 28338 :: 
2023-11-05 18:17:50,228 - root -INFO -checking for the files in the Fact...
2023-11-05 18:17:50,228 - root -INFO -reading file which is of > csv
2023-11-05 18:17:50,228 - Ingest -WARNING -load_files method started
2023-11-05 18:17:57,053 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 18:17:57,054 - root -INFO -displaying the df_fact dataframe
2023-11-05 18:17:57,054 - Ingest -WARNING -here to count the records in the df_fact
2023-11-05 18:17:58,105 - Ingest -WARNING -number of records 1329329 :: 
2023-11-05 18:17:58,105 - root -INFO -implementing data processing methods....
2023-11-05 18:17:58,235 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-05 18:17:58,268 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-05 18:17:59,723 - root -INFO -Application done...
2023-11-05 21:31:21,241 - root -INFO -i am in main method...
2023-11-05 21:31:21,242 - Create_spark -INFO -get_spark_object method started...
2023-11-05 21:31:21,242 - Create_spark -INFO -master is local[*]
2023-11-05 21:31:30,082 - root -INFO -Validating spark object.......
2023-11-05 21:31:30,083 - Validate -WARNING -Started get_current_date method ...
2023-11-05 21:31:32,770 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 21:31:32,770 - Validate -WARNING -Validation done... go ahead
2023-11-05 21:31:32,770 - root -INFO -reading file which is of > parquet
2023-11-05 21:31:32,770 - Ingest -WARNING -load_files method started
2023-11-05 21:31:33,395 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:31:33,395 - root -INFO -displaying file
2023-11-05 21:31:33,395 - root -INFO -here to validate the df
2023-11-05 21:31:33,395 - Ingest -WARNING -here to count the records in the df_city
2023-11-05 21:31:33,898 - Ingest -WARNING -number of records 28338 :: 
2023-11-05 21:31:33,898 - root -INFO -checking for the files in the Fact...
2023-11-05 21:31:33,898 - root -INFO -reading file which is of > csv
2023-11-05 21:31:33,898 - Ingest -WARNING -load_files method started
2023-11-05 21:31:37,627 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:31:37,627 - root -INFO -displaying the df_fact dataframe
2023-11-05 21:31:37,628 - Ingest -WARNING -here to count the records in the df_fact
2023-11-05 21:31:38,140 - Ingest -WARNING -number of records 1329329 :: 
2023-11-05 21:31:38,141 - root -INFO -implementing data processing methods....
2023-11-05 21:31:38,181 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-05 21:31:38,194 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-05 21:31:39,020 - root -INFO -validating schema for dataframes...
2023-11-05 21:31:39,021 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-05 21:31:39,035 - Validate -INFO -	StructField(city,StringType,true)
2023-11-05 21:31:39,035 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-05 21:31:39,035 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-05 21:31:39,036 - Validate -INFO -	StructField(country_name,StringType,true)
2023-11-05 21:31:39,036 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-05 21:31:39,036 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-05 21:31:39,036 - Validate -INFO -print schema done go forward
2023-11-05 21:31:39,036 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-05 21:31:39,040 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-05 21:31:39,040 - Validate -INFO -	StructField(presc_lname,StringType,true)
2023-11-05 21:31:39,040 - Validate -INFO -	StructField(presc_fname,StringType,true)
2023-11-05 21:31:39,040 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-05 21:31:39,040 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-05 21:31:39,040 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-05 21:31:39,041 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-05 21:31:39,041 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-05 21:31:39,041 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-05 21:31:39,041 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-05 21:31:39,041 - Validate -INFO -	StructField(years_of_exp,StringType,true)
2023-11-05 21:31:39,041 - Validate -INFO -print schema done go forward
2023-11-05 21:31:39,041 - root -INFO -Application done...
2023-11-05 21:37:00,269 - root -INFO -i am in main method...
2023-11-05 21:37:00,269 - Create_spark -INFO -get_spark_object method started...
2023-11-05 21:37:00,269 - Create_spark -INFO -master is local[*]
2023-11-05 21:37:10,057 - root -INFO -Validating spark object.......
2023-11-05 21:37:10,058 - Validate -WARNING -Started get_current_date method ...
2023-11-05 21:37:13,807 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 21:37:13,807 - Validate -WARNING -Validation done... go ahead
2023-11-05 21:37:13,807 - root -INFO -reading file which is of > parquet
2023-11-05 21:37:13,807 - Ingest -WARNING -load_files method started
2023-11-05 21:37:14,752 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:37:14,752 - root -INFO -displaying file
2023-11-05 21:37:14,752 - root -INFO -here to validate the df
2023-11-05 21:37:14,753 - Ingest -WARNING -here to count the records in the df_city
2023-11-05 21:37:15,559 - Ingest -WARNING -number of records 28338 :: 
2023-11-05 21:37:15,560 - root -INFO -checking for the files in the Fact...
2023-11-05 21:37:15,560 - root -INFO -reading file which is of > csv
2023-11-05 21:37:15,560 - Ingest -WARNING -load_files method started
2023-11-05 21:37:19,885 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:37:19,885 - root -INFO -displaying the df_fact dataframe
2023-11-05 21:37:19,886 - Ingest -WARNING -here to count the records in the df_fact
2023-11-05 21:37:20,406 - Ingest -WARNING -number of records 1329329 :: 
2023-11-05 21:37:20,406 - root -INFO -implementing data processing methods....
2023-11-05 21:37:20,446 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-05 21:37:20,464 - Data_processing -WARNING -Adding a new column to df_presc_sel...
2023-11-05 21:37:20,517 - Data_processing -WARNING -convert years_of_exp from string to Int & replacing =...
2023-11-05 21:37:20,544 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-05 21:37:21,194 - root -INFO -validating schema for dataframes...
2023-11-05 21:37:21,194 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-05 21:37:21,195 - Validate -INFO -	StructField(city,StringType,true)
2023-11-05 21:37:21,195 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-05 21:37:21,195 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-05 21:37:21,195 - Validate -INFO -	StructField(country_name,StringType,true)
2023-11-05 21:37:21,196 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-05 21:37:21,196 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-05 21:37:21,196 - Validate -INFO -print schema done go forward
2023-11-05 21:37:21,196 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-05 21:37:21,197 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-05 21:37:21,197 - Validate -INFO -	StructField(presc_lname,StringType,true)
2023-11-05 21:37:21,197 - Validate -INFO -	StructField(presc_fname,StringType,true)
2023-11-05 21:37:21,197 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-05 21:37:21,197 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-05 21:37:21,197 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-05 21:37:21,197 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-05 21:37:21,198 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-05 21:37:21,198 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-05 21:37:21,198 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-05 21:37:21,198 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-11-05 21:37:21,198 - Validate -INFO -	StructField(country_name,StringType,false)
2023-11-05 21:37:21,198 - Validate -INFO -print schema done go forward
2023-11-05 21:37:21,198 - root -INFO -Application done...
2023-11-05 21:40:52,004 - root -INFO -i am in main method...
2023-11-05 21:40:52,004 - Create_spark -INFO -get_spark_object method started...
2023-11-05 21:40:52,004 - Create_spark -INFO -master is local[*]
2023-11-05 21:41:01,924 - root -INFO -Validating spark object.......
2023-11-05 21:41:01,924 - Validate -WARNING -Started get_current_date method ...
2023-11-05 21:41:05,136 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 21:41:05,136 - Validate -WARNING -Validation done... go ahead
2023-11-05 21:41:05,136 - root -INFO -reading file which is of > parquet
2023-11-05 21:41:05,136 - Ingest -WARNING -load_files method started
2023-11-05 21:41:05,813 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:41:05,813 - root -INFO -displaying file
2023-11-05 21:41:05,813 - root -INFO -here to validate the df
2023-11-05 21:41:05,813 - Ingest -WARNING -here to count the records in the df_city
2023-11-05 21:41:06,402 - Ingest -WARNING -number of records 28338 :: 
2023-11-05 21:41:06,402 - root -INFO -checking for the files in the Fact...
2023-11-05 21:41:06,403 - root -INFO -reading file which is of > csv
2023-11-05 21:41:06,403 - Ingest -WARNING -load_files method started
2023-11-05 21:41:10,789 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:41:10,790 - root -INFO -displaying the df_fact dataframe
2023-11-05 21:41:10,790 - Ingest -WARNING -here to count the records in the df_fact
2023-11-05 21:41:11,387 - Ingest -WARNING -number of records 1329329 :: 
2023-11-05 21:41:11,387 - root -INFO -implementing data processing methods....
2023-11-05 21:41:11,434 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-05 21:41:11,449 - Data_processing -WARNING -Adding a new column to df_presc_sel...
2023-11-05 21:41:11,505 - Data_processing -WARNING -convert years_of_exp from string to Int & replacing =...
2023-11-05 21:41:11,541 - Data_processing -WARNING -concatenate first and last name column
2023-11-05 21:41:11,573 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-05 21:41:12,267 - root -INFO -validating schema for dataframes...
2023-11-05 21:41:12,267 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-05 21:41:12,268 - Validate -INFO -	StructField(city,StringType,true)
2023-11-05 21:41:12,268 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-05 21:41:12,268 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-05 21:41:12,269 - Validate -INFO -	StructField(country_name,StringType,true)
2023-11-05 21:41:12,269 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-05 21:41:12,269 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-05 21:41:12,269 - Validate -INFO -print schema done go forward
2023-11-05 21:41:12,269 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-05 21:41:12,271 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-05 21:41:12,271 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-05 21:41:12,272 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-05 21:41:12,272 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-05 21:41:12,272 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-05 21:41:12,272 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-05 21:41:12,272 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-05 21:41:12,272 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-05 21:41:12,273 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-11-05 21:41:12,273 - Validate -INFO -	StructField(country_name,StringType,false)
2023-11-05 21:41:12,273 - Validate -INFO -	StructField(presc_full_name,StringType,false)
2023-11-05 21:41:12,273 - Validate -INFO -print schema done go forward
2023-11-05 21:41:12,274 - root -INFO -Application done...
2023-11-05 21:42:34,889 - root -INFO -i am in main method...
2023-11-05 21:42:34,890 - Create_spark -INFO -get_spark_object method started...
2023-11-05 21:42:34,890 - Create_spark -INFO -master is local[*]
2023-11-05 21:42:45,228 - root -INFO -Validating spark object.......
2023-11-05 21:42:45,228 - Validate -WARNING -Started get_current_date method ...
2023-11-05 21:42:48,763 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 21:42:48,763 - Validate -WARNING -Validation done... go ahead
2023-11-05 21:42:48,764 - root -INFO -reading file which is of > parquet
2023-11-05 21:42:48,764 - Ingest -WARNING -load_files method started
2023-11-05 21:42:49,425 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:42:49,425 - root -INFO -displaying file
2023-11-05 21:42:49,425 - root -INFO -here to validate the df
2023-11-05 21:42:49,425 - Ingest -WARNING -here to count the records in the df_city
2023-11-05 21:42:49,967 - Ingest -WARNING -number of records 28338 :: 
2023-11-05 21:42:49,967 - root -INFO -checking for the files in the Fact...
2023-11-05 21:42:49,968 - root -INFO -reading file which is of > csv
2023-11-05 21:42:49,968 - Ingest -WARNING -load_files method started
2023-11-05 21:42:53,857 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:42:53,857 - root -INFO -displaying the df_fact dataframe
2023-11-05 21:42:53,857 - Ingest -WARNING -here to count the records in the df_fact
2023-11-05 21:42:54,432 - Ingest -WARNING -number of records 1329329 :: 
2023-11-05 21:42:54,432 - root -INFO -implementing data processing methods....
2023-11-05 21:42:54,476 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-05 21:42:54,491 - Data_processing -WARNING -Adding a new column to df_presc_sel...
2023-11-05 21:42:54,580 - Data_processing -WARNING -convert years_of_exp from string to Int & replacing =...
2023-11-05 21:42:54,632 - Data_processing -WARNING -concatenate first and last name column
2023-11-05 21:42:54,662 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-05 21:42:55,390 - root -INFO -validating schema for dataframes...
2023-11-05 21:42:55,390 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-05 21:42:55,393 - Validate -INFO -	StructField(city,StringType,true)
2023-11-05 21:42:55,393 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-05 21:42:55,393 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-05 21:42:55,393 - Validate -INFO -	StructField(country_name,StringType,true)
2023-11-05 21:42:55,393 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-05 21:42:55,393 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-05 21:42:55,393 - Validate -INFO -print schema done go forward
2023-11-05 21:42:55,393 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-05 21:42:55,395 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-05 21:42:55,395 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-05 21:42:55,395 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-05 21:42:55,395 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-05 21:42:55,395 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-05 21:42:55,395 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-05 21:42:55,395 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-05 21:42:55,396 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-05 21:42:55,396 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-11-05 21:42:55,396 - Validate -INFO -	StructField(country_name,StringType,false)
2023-11-05 21:42:55,396 - Validate -INFO -	StructField(presc_full_name,StringType,false)
2023-11-05 21:42:55,396 - Validate -INFO -print schema done go forward
2023-11-05 21:42:55,396 - root -INFO -Application done...
2023-11-05 21:45:50,876 - root -INFO -i am in main method...
2023-11-05 21:45:50,877 - Create_spark -INFO -get_spark_object method started...
2023-11-05 21:45:50,877 - Create_spark -INFO -master is local[*]
2023-11-05 21:46:00,195 - root -INFO -Validating spark object.......
2023-11-05 21:46:00,195 - Validate -WARNING -Started get_current_date method ...
2023-11-05 21:46:03,878 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 21:46:03,878 - Validate -WARNING -Validation done... go ahead
2023-11-05 21:46:03,878 - root -INFO -reading file which is of > parquet
2023-11-05 21:46:03,878 - Ingest -WARNING -load_files method started
2023-11-05 21:46:04,615 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:46:04,616 - root -INFO -displaying file
2023-11-05 21:46:04,616 - root -INFO -here to validate the df
2023-11-05 21:46:04,616 - Ingest -WARNING -here to count the records in the df_city
2023-11-05 21:46:05,268 - Ingest -WARNING -number of records 28338 :: 
2023-11-05 21:46:05,268 - root -INFO -checking for the files in the Fact...
2023-11-05 21:46:05,268 - root -INFO -reading file which is of > csv
2023-11-05 21:46:05,268 - Ingest -WARNING -load_files method started
2023-11-05 21:46:09,501 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:46:09,501 - root -INFO -displaying the df_fact dataframe
2023-11-05 21:46:09,501 - Ingest -WARNING -here to count the records in the df_fact
2023-11-05 21:46:10,102 - Ingest -WARNING -number of records 1329329 :: 
2023-11-05 21:46:10,102 - root -INFO -implementing data processing methods....
2023-11-05 21:46:10,158 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-05 21:46:10,175 - Data_processing -WARNING -Adding a new column to df_presc_sel...
2023-11-05 21:46:10,245 - Data_processing -WARNING -convert years_of_exp from string to Int & replacing =...
2023-11-05 21:46:10,301 - Data_processing -WARNING -concatenate first and last name column
2023-11-05 21:46:10,338 - Data_processing -WARNING -now check for null values in all columns
2023-11-05 21:46:10,650 - Data_processing -WARNING -drop null values in respective columns
2023-11-05 21:46:10,651 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-05 21:46:18,418 - root -INFO -validating schema for dataframes...
2023-11-05 21:46:18,418 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-05 21:46:18,419 - Validate -INFO -	StructField(city,StringType,true)
2023-11-05 21:46:18,419 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-05 21:46:18,419 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-05 21:46:18,419 - Validate -INFO -	StructField(country_name,StringType,true)
2023-11-05 21:46:18,420 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-05 21:46:18,420 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-05 21:46:18,420 - Validate -INFO -print schema done go forward
2023-11-05 21:46:18,420 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-05 21:46:18,420 - Validate -INFO -	StructField(presc_id,LongType,false)
2023-11-05 21:46:18,421 - Validate -INFO -	StructField(presc_city,LongType,false)
2023-11-05 21:46:18,421 - Validate -INFO -	StructField(presc_state,LongType,false)
2023-11-05 21:46:18,421 - Validate -INFO -	StructField(presc_spclt,LongType,false)
2023-11-05 21:46:18,421 - Validate -INFO -	StructField(drug_name,LongType,false)
2023-11-05 21:46:18,421 - Validate -INFO -	StructField(tx_cnt,LongType,false)
2023-11-05 21:46:18,421 - Validate -INFO -	StructField(total_day_supply,LongType,false)
2023-11-05 21:46:18,421 - Validate -INFO -	StructField(total_drug_cost,LongType,false)
2023-11-05 21:46:18,421 - Validate -INFO -	StructField(years_of_exp,LongType,false)
2023-11-05 21:46:18,421 - Validate -INFO -	StructField(country_name,LongType,false)
2023-11-05 21:46:18,421 - Validate -INFO -	StructField(presc_full_name,LongType,false)
2023-11-05 21:46:18,421 - Validate -INFO -print schema done go forward
2023-11-05 21:46:18,421 - root -INFO -Application done...
2023-11-05 21:48:03,483 - root -INFO -i am in main method...
2023-11-05 21:48:03,483 - Create_spark -INFO -get_spark_object method started...
2023-11-05 21:48:03,483 - Create_spark -INFO -master is local[*]
2023-11-05 21:48:13,221 - root -INFO -Validating spark object.......
2023-11-05 21:48:13,221 - Validate -WARNING -Started get_current_date method ...
2023-11-05 21:48:17,186 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 21:48:17,186 - Validate -WARNING -Validation done... go ahead
2023-11-05 21:48:17,186 - root -INFO -reading file which is of > parquet
2023-11-05 21:48:17,186 - Ingest -WARNING -load_files method started
2023-11-05 21:48:18,078 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:48:18,078 - root -INFO -displaying file
2023-11-05 21:48:18,079 - root -INFO -here to validate the df
2023-11-05 21:48:18,079 - Ingest -WARNING -here to count the records in the df_city
2023-11-05 21:48:18,828 - Ingest -WARNING -number of records 28338 :: 
2023-11-05 21:48:18,829 - root -INFO -checking for the files in the Fact...
2023-11-05 21:48:18,829 - root -INFO -reading file which is of > csv
2023-11-05 21:48:18,829 - Ingest -WARNING -load_files method started
2023-11-05 21:48:23,144 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:48:23,144 - root -INFO -displaying the df_fact dataframe
2023-11-05 21:48:23,144 - Ingest -WARNING -here to count the records in the df_fact
2023-11-05 21:48:23,784 - Ingest -WARNING -number of records 1329329 :: 
2023-11-05 21:48:23,784 - root -INFO -implementing data processing methods....
2023-11-05 21:48:23,842 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-05 21:48:23,864 - Data_processing -WARNING -Adding a new column to df_presc_sel...
2023-11-05 21:48:23,945 - Data_processing -WARNING -convert years_of_exp from string to Int & replacing =...
2023-11-05 21:48:24,000 - Data_processing -WARNING -concatenate first and last name column
2023-11-05 21:48:24,042 - Data_processing -WARNING -now check for null values in all columns
2023-11-05 21:48:24,335 - Data_processing -WARNING -drop null values in respective columns
2023-11-05 21:48:24,359 - Data_processing -WARNING -successfully droped the null values....
2023-11-05 21:48:24,359 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-05 21:48:31,341 - root -INFO -validating schema for dataframes...
2023-11-05 21:48:31,341 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-05 21:48:31,342 - Validate -INFO -	StructField(city,StringType,true)
2023-11-05 21:48:31,342 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-05 21:48:31,342 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-05 21:48:31,343 - Validate -INFO -	StructField(country_name,StringType,true)
2023-11-05 21:48:31,343 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-05 21:48:31,343 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-05 21:48:31,343 - Validate -INFO -print schema done go forward
2023-11-05 21:48:31,343 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-05 21:48:31,344 - Validate -INFO -	StructField(presc_id,LongType,false)
2023-11-05 21:48:31,344 - Validate -INFO -	StructField(presc_city,LongType,false)
2023-11-05 21:48:31,344 - Validate -INFO -	StructField(presc_state,LongType,false)
2023-11-05 21:48:31,344 - Validate -INFO -	StructField(presc_spclt,LongType,false)
2023-11-05 21:48:31,344 - Validate -INFO -	StructField(drug_name,LongType,false)
2023-11-05 21:48:31,344 - Validate -INFO -	StructField(tx_cnt,LongType,false)
2023-11-05 21:48:31,344 - Validate -INFO -	StructField(total_day_supply,LongType,false)
2023-11-05 21:48:31,344 - Validate -INFO -	StructField(total_drug_cost,LongType,false)
2023-11-05 21:48:31,344 - Validate -INFO -	StructField(years_of_exp,LongType,false)
2023-11-05 21:48:31,344 - Validate -INFO -	StructField(country_name,LongType,false)
2023-11-05 21:48:31,344 - Validate -INFO -	StructField(presc_full_name,LongType,false)
2023-11-05 21:48:31,344 - Validate -INFO -print schema done go forward
2023-11-05 21:48:31,344 - root -INFO -Application done...
2023-11-05 21:49:57,975 - root -INFO -i am in main method...
2023-11-05 21:49:57,975 - Create_spark -INFO -get_spark_object method started...
2023-11-05 21:49:57,975 - Create_spark -INFO -master is local[*]
2023-11-05 21:50:07,092 - root -INFO -Validating spark object.......
2023-11-05 21:50:07,092 - Validate -WARNING -Started get_current_date method ...
2023-11-05 21:50:09,808 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 21:50:09,808 - Validate -WARNING -Validation done... go ahead
2023-11-05 21:50:09,808 - root -INFO -reading file which is of > parquet
2023-11-05 21:50:09,808 - Ingest -WARNING -load_files method started
2023-11-05 21:50:10,390 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:50:10,390 - root -INFO -displaying file
2023-11-05 21:50:10,390 - root -INFO -here to validate the df
2023-11-05 21:50:10,390 - Ingest -WARNING -here to count the records in the df_city
2023-11-05 21:50:10,918 - Ingest -WARNING -number of records 28338 :: 
2023-11-05 21:50:10,918 - root -INFO -checking for the files in the Fact...
2023-11-05 21:50:10,919 - root -INFO -reading file which is of > csv
2023-11-05 21:50:10,919 - Ingest -WARNING -load_files method started
2023-11-05 21:50:14,914 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:50:14,915 - root -INFO -displaying the df_fact dataframe
2023-11-05 21:50:14,915 - Ingest -WARNING -here to count the records in the df_fact
2023-11-05 21:50:15,561 - Ingest -WARNING -number of records 1329329 :: 
2023-11-05 21:50:15,561 - root -INFO -implementing data processing methods....
2023-11-05 21:50:15,613 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-05 21:50:15,633 - Data_processing -WARNING -Adding a new column to df_presc_sel...
2023-11-05 21:50:15,708 - Data_processing -WARNING -convert years_of_exp from string to Int & replacing =...
2023-11-05 21:50:15,746 - Data_processing -WARNING -concatenate first and last name column
2023-11-05 21:50:15,790 - Data_processing -WARNING -now check for null values in all columns
2023-11-05 21:50:16,070 - Data_processing -WARNING -drop null values in respective columns
2023-11-05 21:50:16,091 - Data_processing -WARNING -successfully droped the null values....
2023-11-05 21:50:16,091 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-05 21:50:23,819 - root -INFO -validating schema for dataframes...
2023-11-05 21:50:23,819 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-05 21:50:23,820 - Validate -INFO -	StructField(city,StringType,true)
2023-11-05 21:50:23,820 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-05 21:50:23,820 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-05 21:50:23,820 - Validate -INFO -	StructField(country_name,StringType,true)
2023-11-05 21:50:23,820 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-05 21:50:23,821 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-05 21:50:23,821 - Validate -INFO -print schema done go forward
2023-11-05 21:50:23,821 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-05 21:50:23,823 - Validate -INFO -	StructField(presc_id,LongType,false)
2023-11-05 21:50:23,823 - Validate -INFO -	StructField(presc_city,LongType,false)
2023-11-05 21:50:23,823 - Validate -INFO -	StructField(presc_state,LongType,false)
2023-11-05 21:50:23,823 - Validate -INFO -	StructField(presc_spclt,LongType,false)
2023-11-05 21:50:23,823 - Validate -INFO -	StructField(drug_name,LongType,false)
2023-11-05 21:50:23,823 - Validate -INFO -	StructField(tx_cnt,LongType,false)
2023-11-05 21:50:23,823 - Validate -INFO -	StructField(total_day_supply,LongType,false)
2023-11-05 21:50:23,823 - Validate -INFO -	StructField(total_drug_cost,LongType,false)
2023-11-05 21:50:23,823 - Validate -INFO -	StructField(years_of_exp,LongType,false)
2023-11-05 21:50:23,823 - Validate -INFO -	StructField(country_name,LongType,false)
2023-11-05 21:50:23,824 - Validate -INFO -	StructField(presc_full_name,LongType,false)
2023-11-05 21:50:23,824 - Validate -INFO -print schema done go forward
2023-11-05 21:50:29,796 - root -INFO -Application done...
2023-11-05 21:52:50,212 - root -INFO -i am in main method...
2023-11-05 21:52:50,212 - Create_spark -INFO -get_spark_object method started...
2023-11-05 21:52:50,212 - Create_spark -INFO -master is local[*]
2023-11-05 21:52:59,486 - root -INFO -Validating spark object.......
2023-11-05 21:52:59,487 - Validate -WARNING -Started get_current_date method ...
2023-11-05 21:53:03,008 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 5))]
2023-11-05 21:53:03,008 - Validate -WARNING -Validation done... go ahead
2023-11-05 21:53:03,008 - root -INFO -reading file which is of > parquet
2023-11-05 21:53:03,008 - Ingest -WARNING -load_files method started
2023-11-05 21:53:03,690 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:53:03,690 - root -INFO -displaying file
2023-11-05 21:53:03,690 - root -INFO -here to validate the df
2023-11-05 21:53:03,690 - Ingest -WARNING -here to count the records in the df_city
2023-11-05 21:53:04,294 - Ingest -WARNING -number of records 28338 :: 
2023-11-05 21:53:04,295 - root -INFO -checking for the files in the Fact...
2023-11-05 21:53:04,295 - root -INFO -reading file which is of > csv
2023-11-05 21:53:04,295 - Ingest -WARNING -load_files method started
2023-11-05 21:53:08,257 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-05 21:53:08,257 - root -INFO -displaying the df_fact dataframe
2023-11-05 21:53:08,258 - Ingest -WARNING -here to count the records in the df_fact
2023-11-05 21:53:08,795 - Ingest -WARNING -number of records 1329329 :: 
2023-11-05 21:53:08,796 - root -INFO -implementing data processing methods....
2023-11-05 21:53:08,796 - Data_processing -WARNING -data_clean method() started...
2023-11-05 21:53:08,796 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-05 21:53:08,842 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-05 21:53:08,854 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-05 21:53:08,904 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-05 21:53:08,943 - Data_processing -WARNING -concat first and lname 
2023-11-05 21:53:08,963 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-05 21:53:08,973 - Data_processing -WARNING -now check for null values in all columns
2023-11-05 21:53:09,215 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-05 21:53:09,233 - Data_processing -WARNING -successfully droped the null values....
2023-11-05 21:53:09,439 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-05 21:53:15,767 - root -INFO -validating schema for dataframes...
2023-11-05 21:53:15,767 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-05 21:53:15,767 - Validate -INFO -	StructField(city,StringType,true)
2023-11-05 21:53:15,767 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-05 21:53:15,767 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-05 21:53:15,767 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-05 21:53:15,768 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-05 21:53:15,768 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-05 21:53:15,768 - Validate -INFO -print schema done go forward
2023-11-05 21:53:15,768 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-05 21:53:15,768 - Validate -INFO -	StructField(presc_id,LongType,false)
2023-11-05 21:53:15,769 - Validate -INFO -	StructField(presc_city,LongType,false)
2023-11-05 21:53:15,769 - Validate -INFO -	StructField(presc_state,LongType,false)
2023-11-05 21:53:15,769 - Validate -INFO -	StructField(presc_spclt,LongType,false)
2023-11-05 21:53:15,769 - Validate -INFO -	StructField(drug_name,LongType,false)
2023-11-05 21:53:15,769 - Validate -INFO -	StructField(tx_cnt,LongType,false)
2023-11-05 21:53:15,769 - Validate -INFO -	StructField(total_day_supply,LongType,false)
2023-11-05 21:53:15,769 - Validate -INFO -	StructField(total_drug_cost,LongType,false)
2023-11-05 21:53:15,769 - Validate -INFO -	StructField(years_of_exp,LongType,false)
2023-11-05 21:53:15,769 - Validate -INFO -	StructField(Country_name,LongType,false)
2023-11-05 21:53:15,769 - Validate -INFO -	StructField(presc_fullname,LongType,false)
2023-11-05 21:53:15,769 - Validate -INFO -print schema done go forward
2023-11-05 21:53:20,852 - root -INFO -Application done...
2023-11-06 09:47:58,849 - root -INFO -i am in main method...
2023-11-06 09:47:58,849 - Create_spark -INFO -get_spark_object method started...
2023-11-06 09:47:58,849 - Create_spark -INFO -master is local[*]
2023-11-06 09:48:20,937 - root -INFO -Validating spark object.......
2023-11-06 09:48:20,938 - Validate -WARNING -Started get_current_date method ...
2023-11-06 09:48:25,221 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 6))]
2023-11-06 09:48:25,221 - Validate -WARNING -Validation done... go ahead
2023-11-06 09:48:25,222 - root -INFO -reading file which is of > parquet
2023-11-06 09:48:25,222 - Ingest -WARNING -load_files method started
2023-11-06 09:48:26,233 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 09:48:26,233 - root -INFO -displaying file
2023-11-06 09:48:26,233 - root -INFO -here to validate the df
2023-11-06 09:48:26,234 - Ingest -WARNING -here to count the records in the df_city
2023-11-06 09:48:26,966 - Ingest -WARNING -number of records 28338 :: 
2023-11-06 09:48:26,966 - root -INFO -checking for the files in the Fact...
2023-11-06 09:48:26,966 - root -INFO -reading file which is of > csv
2023-11-06 09:48:26,966 - Ingest -WARNING -load_files method started
2023-11-06 09:48:35,503 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 09:48:35,503 - root -INFO -displaying the df_fact dataframe
2023-11-06 09:48:35,503 - Ingest -WARNING -here to count the records in the df_fact
2023-11-06 09:48:36,197 - Ingest -WARNING -number of records 1329329 :: 
2023-11-06 09:48:36,197 - root -INFO -implementing data processing methods....
2023-11-06 09:48:36,197 - Data_processing -WARNING -data_clean method() started...
2023-11-06 09:48:36,197 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-06 09:48:36,245 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-06 09:48:36,261 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-06 09:48:36,312 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-06 09:48:36,312 - Data_processing -WARNING -concat first and lname 
2023-11-06 09:48:36,338 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-06 09:48:36,346 - Data_processing -WARNING -now check for null values in all columns
2023-11-06 09:48:36,603 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-06 09:48:36,626 - Data_processing -WARNING -successfully droped the null values....
2023-11-06 09:48:36,831 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-06 09:48:46,771 - root -INFO -validating schema for dataframes...
2023-11-06 09:48:46,771 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-06 09:48:46,772 - Validate -INFO -	StructField(city,StringType,true)
2023-11-06 09:48:46,772 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-06 09:48:46,772 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-06 09:48:46,772 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-06 09:48:46,772 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-06 09:48:46,773 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-06 09:48:46,773 - Validate -INFO -print schema done go forward
2023-11-06 09:48:46,773 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-06 09:48:46,774 - Validate -INFO -	StructField(presc_id,LongType,false)
2023-11-06 09:48:46,774 - Validate -INFO -	StructField(presc_city,LongType,false)
2023-11-06 09:48:46,774 - Validate -INFO -	StructField(presc_state,LongType,false)
2023-11-06 09:48:46,774 - Validate -INFO -	StructField(presc_spclt,LongType,false)
2023-11-06 09:48:46,774 - Validate -INFO -	StructField(drug_name,LongType,false)
2023-11-06 09:48:46,774 - Validate -INFO -	StructField(tx_cnt,LongType,false)
2023-11-06 09:48:46,774 - Validate -INFO -	StructField(total_day_supply,LongType,false)
2023-11-06 09:48:46,774 - Validate -INFO -	StructField(total_drug_cost,LongType,false)
2023-11-06 09:48:46,774 - Validate -INFO -	StructField(years_of_exp,LongType,false)
2023-11-06 09:48:46,775 - Validate -INFO -	StructField(Country_name,LongType,false)
2023-11-06 09:48:46,775 - Validate -INFO -	StructField(presc_fullname,LongType,false)
2023-11-06 09:48:46,775 - Validate -INFO -print schema done go forward
2023-11-06 09:48:53,150 - root -INFO -Application done...
2023-11-06 09:51:06,668 - root -INFO -i am in main method...
2023-11-06 09:51:06,669 - Create_spark -INFO -get_spark_object method started...
2023-11-06 09:51:06,669 - Create_spark -INFO -master is local[*]
2023-11-06 09:51:16,304 - root -INFO -Validating spark object.......
2023-11-06 09:51:16,304 - Validate -WARNING -Started get_current_date method ...
2023-11-06 09:51:19,022 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 6))]
2023-11-06 09:51:19,022 - Validate -WARNING -Validation done... go ahead
2023-11-06 09:51:19,022 - root -INFO -reading file which is of > parquet
2023-11-06 09:51:19,022 - Ingest -WARNING -load_files method started
2023-11-06 09:51:19,692 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 09:51:19,692 - root -INFO -displaying file
2023-11-06 09:51:19,692 - root -INFO -here to validate the df
2023-11-06 09:51:19,692 - Ingest -WARNING -here to count the records in the df_city
2023-11-06 09:51:20,393 - Ingest -WARNING -number of records 28338 :: 
2023-11-06 09:51:20,394 - root -INFO -checking for the files in the Fact...
2023-11-06 09:51:20,394 - root -INFO -reading file which is of > csv
2023-11-06 09:51:20,394 - Ingest -WARNING -load_files method started
2023-11-06 09:51:24,918 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 09:51:24,918 - root -INFO -displaying the df_fact dataframe
2023-11-06 09:51:24,918 - Ingest -WARNING -here to count the records in the df_fact
2023-11-06 09:51:25,625 - Ingest -WARNING -number of records 1329329 :: 
2023-11-06 09:51:25,626 - root -INFO -implementing data processing methods....
2023-11-06 09:51:25,626 - Data_processing -WARNING -data_clean method() started...
2023-11-06 09:51:25,626 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-06 09:51:25,671 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-06 09:51:25,688 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-06 09:51:25,742 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-06 09:51:25,742 - Data_processing -WARNING -concat first and lname 
2023-11-06 09:51:25,772 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-06 09:51:25,781 - Data_processing -WARNING -now check for null values in all columns
2023-11-06 09:51:25,782 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-06 09:51:25,800 - Data_processing -WARNING -successfully droped the null values....
2023-11-06 09:51:25,800 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-06 09:51:26,547 - root -INFO -validating schema for dataframes...
2023-11-06 09:51:26,547 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-06 09:51:26,549 - Validate -INFO -	StructField(city,StringType,true)
2023-11-06 09:51:26,549 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-06 09:51:26,549 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-06 09:51:26,549 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-06 09:51:26,549 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-06 09:51:26,549 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-06 09:51:26,549 - Validate -INFO -print schema done go forward
2023-11-06 09:51:26,549 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-06 09:51:26,551 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-06 09:51:26,552 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-06 09:51:26,553 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-06 09:51:26,553 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-06 09:51:26,553 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-06 09:51:26,553 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-06 09:51:26,554 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-06 09:51:26,554 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-06 09:51:26,554 - Validate -INFO -	StructField(years_of_exp,StringType,true)
2023-11-06 09:51:26,554 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-06 09:51:26,554 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-06 09:51:26,554 - Validate -INFO -print schema done go forward
2023-11-06 09:51:26,794 - root -INFO -Application done...
2023-11-06 09:52:24,723 - root -INFO -i am in main method...
2023-11-06 09:52:24,724 - Create_spark -INFO -get_spark_object method started...
2023-11-06 09:52:24,724 - Create_spark -INFO -master is local[*]
2023-11-06 09:52:34,217 - root -INFO -Validating spark object.......
2023-11-06 09:52:34,217 - Validate -WARNING -Started get_current_date method ...
2023-11-06 09:52:38,974 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 6))]
2023-11-06 09:52:38,975 - Validate -WARNING -Validation done... go ahead
2023-11-06 09:52:38,975 - root -INFO -reading file which is of > parquet
2023-11-06 09:52:38,975 - Ingest -WARNING -load_files method started
2023-11-06 09:52:40,408 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 09:52:40,409 - root -INFO -displaying file
2023-11-06 09:52:40,409 - root -INFO -here to validate the df
2023-11-06 09:52:40,409 - Ingest -WARNING -here to count the records in the df_city
2023-11-06 09:52:41,437 - Ingest -WARNING -number of records 28338 :: 
2023-11-06 09:52:41,437 - root -INFO -checking for the files in the Fact...
2023-11-06 09:52:41,437 - root -INFO -reading file which is of > csv
2023-11-06 09:52:41,438 - Ingest -WARNING -load_files method started
2023-11-06 09:52:47,991 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 09:52:47,991 - root -INFO -displaying the df_fact dataframe
2023-11-06 09:52:47,993 - Ingest -WARNING -here to count the records in the df_fact
2023-11-06 09:52:48,956 - Ingest -WARNING -number of records 1329329 :: 
2023-11-06 09:52:48,956 - root -INFO -implementing data processing methods....
2023-11-06 09:52:48,956 - Data_processing -WARNING -data_clean method() started...
2023-11-06 09:52:48,957 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-06 09:52:49,046 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-06 09:52:49,082 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-06 09:52:49,194 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-06 09:52:49,289 - Data_processing -WARNING -concat first and lname 
2023-11-06 09:52:49,325 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-06 09:52:49,338 - Data_processing -WARNING -now check for null values in all columns
2023-11-06 09:52:49,338 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-06 09:52:49,360 - Data_processing -WARNING -successfully droped the null values....
2023-11-06 09:52:49,360 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-06 09:52:50,835 - root -INFO -validating schema for dataframes...
2023-11-06 09:52:50,835 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-06 09:52:50,838 - Validate -INFO -	StructField(city,StringType,true)
2023-11-06 09:52:50,838 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-06 09:52:50,839 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-06 09:52:50,839 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-06 09:52:50,839 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-06 09:52:50,839 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-06 09:52:50,839 - Validate -INFO -print schema done go forward
2023-11-06 09:52:50,839 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-06 09:52:50,842 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-06 09:52:50,842 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-06 09:52:50,843 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-06 09:52:50,843 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-06 09:52:50,843 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-06 09:52:50,843 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-06 09:52:50,843 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-06 09:52:50,843 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-06 09:52:50,844 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-11-06 09:52:50,844 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-06 09:52:50,844 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-06 09:52:50,844 - Validate -INFO -print schema done go forward
2023-11-06 09:52:51,200 - root -INFO -Application done...
2023-11-06 09:55:04,214 - root -INFO -i am in main method...
2023-11-06 09:55:04,214 - Create_spark -INFO -get_spark_object method started...
2023-11-06 09:55:04,214 - Create_spark -INFO -master is local[*]
2023-11-06 09:55:16,083 - root -INFO -Validating spark object.......
2023-11-06 09:55:16,083 - Validate -WARNING -Started get_current_date method ...
2023-11-06 09:55:22,019 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 6))]
2023-11-06 09:55:22,019 - Validate -WARNING -Validation done... go ahead
2023-11-06 09:55:22,019 - root -INFO -reading file which is of > parquet
2023-11-06 09:55:22,020 - Ingest -WARNING -load_files method started
2023-11-06 09:55:23,381 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 09:55:23,381 - root -INFO -displaying file
2023-11-06 09:55:23,381 - root -INFO -here to validate the df
2023-11-06 09:55:23,381 - Ingest -WARNING -here to count the records in the df_city
2023-11-06 09:55:24,548 - Ingest -WARNING -number of records 28338 :: 
2023-11-06 09:55:24,548 - root -INFO -checking for the files in the Fact...
2023-11-06 09:55:24,549 - root -INFO -reading file which is of > csv
2023-11-06 09:55:24,549 - Ingest -WARNING -load_files method started
2023-11-06 09:55:31,071 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 09:55:31,071 - root -INFO -displaying the df_fact dataframe
2023-11-06 09:55:31,071 - Ingest -WARNING -here to count the records in the df_fact
2023-11-06 09:55:31,687 - Ingest -WARNING -number of records 1329329 :: 
2023-11-06 09:55:31,687 - root -INFO -implementing data processing methods....
2023-11-06 09:55:31,687 - Data_processing -WARNING -data_clean method() started...
2023-11-06 09:55:31,687 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-06 09:55:31,731 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-06 09:55:31,749 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-06 09:55:31,801 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-06 09:55:31,825 - Data_processing -WARNING -concat first and lname 
2023-11-06 09:55:31,853 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-06 09:55:31,862 - Data_processing -WARNING -now check for null values in all columns
2023-11-06 09:55:31,863 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-06 09:55:31,880 - Data_processing -WARNING -successfully droped the null values....
2023-11-06 09:55:31,880 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-06 09:55:32,634 - root -INFO -validating schema for dataframes...
2023-11-06 09:55:32,634 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-06 09:55:32,637 - Validate -INFO -	StructField(city,StringType,true)
2023-11-06 09:55:32,637 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-06 09:55:32,637 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-06 09:55:32,637 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-06 09:55:32,638 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-06 09:55:32,638 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-06 09:55:32,638 - Validate -INFO -print schema done go forward
2023-11-06 09:55:32,638 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-06 09:55:32,640 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-06 09:55:32,640 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-06 09:55:32,640 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-06 09:55:32,640 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-06 09:55:32,640 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-06 09:55:32,641 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-06 09:55:32,641 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-06 09:55:32,641 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-06 09:55:32,641 - Validate -INFO -	StructField(years_of_exp,StringType,true)
2023-11-06 09:55:32,641 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-06 09:55:32,641 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-06 09:55:32,641 - Validate -INFO -print schema done go forward
2023-11-06 09:55:32,839 - root -INFO -Application done...
2023-11-06 09:56:13,501 - root -INFO -i am in main method...
2023-11-06 09:56:13,501 - Create_spark -INFO -get_spark_object method started...
2023-11-06 09:56:13,501 - Create_spark -INFO -master is local[*]
2023-11-06 09:56:24,482 - root -INFO -Validating spark object.......
2023-11-06 09:56:24,482 - Validate -WARNING -Started get_current_date method ...
2023-11-06 09:56:27,714 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 6))]
2023-11-06 09:56:27,714 - Validate -WARNING -Validation done... go ahead
2023-11-06 09:56:27,714 - root -INFO -reading file which is of > parquet
2023-11-06 09:56:27,714 - Ingest -WARNING -load_files method started
2023-11-06 09:56:28,333 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 09:56:28,333 - root -INFO -displaying file
2023-11-06 09:56:28,333 - root -INFO -here to validate the df
2023-11-06 09:56:28,333 - Ingest -WARNING -here to count the records in the df_city
2023-11-06 09:56:28,885 - Ingest -WARNING -number of records 28338 :: 
2023-11-06 09:56:28,885 - root -INFO -checking for the files in the Fact...
2023-11-06 09:56:28,885 - root -INFO -reading file which is of > csv
2023-11-06 09:56:28,886 - Ingest -WARNING -load_files method started
2023-11-06 09:56:34,527 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 09:56:34,527 - root -INFO -displaying the df_fact dataframe
2023-11-06 09:56:34,527 - Ingest -WARNING -here to count the records in the df_fact
2023-11-06 09:56:35,519 - Ingest -WARNING -number of records 1329329 :: 
2023-11-06 09:56:35,519 - root -INFO -implementing data processing methods....
2023-11-06 09:56:35,520 - Data_processing -WARNING -data_clean method() started...
2023-11-06 09:56:35,520 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-06 09:56:35,606 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-06 09:56:35,642 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-06 09:56:35,764 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-06 09:56:35,846 - Data_processing -WARNING -concat first and lname 
2023-11-06 09:56:35,883 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-06 09:56:35,901 - Data_processing -WARNING -now check for null values in all columns
2023-11-06 09:56:35,902 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-06 09:56:35,934 - Data_processing -WARNING -successfully droped the null values....
2023-11-06 09:56:35,935 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-06 09:56:37,483 - root -INFO -validating schema for dataframes...
2023-11-06 09:56:37,484 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-06 09:56:37,486 - Validate -INFO -	StructField(city,StringType,true)
2023-11-06 09:56:37,486 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-06 09:56:37,486 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-06 09:56:37,486 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-06 09:56:37,487 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-06 09:56:37,487 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-06 09:56:37,487 - Validate -INFO -print schema done go forward
2023-11-06 09:56:37,487 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-06 09:56:37,489 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-06 09:56:37,490 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-06 09:56:37,490 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-06 09:56:37,490 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-06 09:56:37,490 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-06 09:56:37,490 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-06 09:56:37,490 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-06 09:56:37,490 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-06 09:56:37,491 - Validate -INFO -	StructField(years_of_exp,FloatType,true)
2023-11-06 09:56:37,491 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-06 09:56:37,491 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-06 09:56:37,491 - Validate -INFO -print schema done go forward
2023-11-06 09:56:37,838 - root -INFO -Application done...
2023-11-06 10:27:44,758 - root -INFO -i am in main method...
2023-11-06 10:27:44,758 - Create_spark -INFO -get_spark_object method started...
2023-11-06 10:27:44,759 - Create_spark -INFO -master is local[*]
2023-11-06 10:27:57,732 - root -INFO -Validating spark object.......
2023-11-06 10:27:57,733 - Validate -WARNING -Started get_current_date method ...
2023-11-06 10:28:03,587 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 6))]
2023-11-06 10:28:03,587 - Validate -WARNING -Validation done... go ahead
2023-11-06 10:28:03,587 - root -INFO -reading file which is of > parquet
2023-11-06 10:28:03,588 - Ingest -WARNING -load_files method started
2023-11-06 10:28:04,237 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 10:28:04,237 - root -INFO -displaying file
2023-11-06 10:28:04,237 - root -INFO -here to validate the df
2023-11-06 10:28:04,237 - Ingest -WARNING -here to count the records in the df_city
2023-11-06 10:28:04,800 - Ingest -WARNING -number of records 28338 :: 
2023-11-06 10:28:04,800 - root -INFO -checking for the files in the Fact...
2023-11-06 10:28:04,800 - root -INFO -reading file which is of > csv
2023-11-06 10:28:04,800 - Ingest -WARNING -load_files method started
2023-11-06 10:28:09,885 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 10:28:09,886 - root -INFO -displaying the df_fact dataframe
2023-11-06 10:28:09,886 - Ingest -WARNING -here to count the records in the df_fact
2023-11-06 10:28:10,759 - Ingest -WARNING -number of records 1329329 :: 
2023-11-06 10:28:10,759 - root -INFO -implementing data processing methods....
2023-11-06 10:28:10,760 - Data_processing -WARNING -data_clean method() started...
2023-11-06 10:28:10,760 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-06 10:28:10,809 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-06 10:28:10,828 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-06 10:28:10,885 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-06 10:28:10,926 - Data_processing -WARNING -concat first and lname 
2023-11-06 10:28:10,949 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-06 10:28:10,959 - Data_processing -WARNING -now check for null values in all columns
2023-11-06 10:28:10,959 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-06 10:28:10,977 - Data_processing -WARNING -fill the null values in tx_cnt with the avg value....
2023-11-06 10:28:12,858 - Data_processing -WARNING -successfully dropped the null values....
2023-11-06 10:28:12,858 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-06 10:28:13,667 - root -INFO -validating schema for dataframes...
2023-11-06 10:28:13,667 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-06 10:28:13,668 - Validate -INFO -	StructField(city,StringType,true)
2023-11-06 10:28:13,668 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-06 10:28:13,669 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-06 10:28:13,669 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-06 10:28:13,669 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-06 10:28:13,669 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-06 10:28:13,669 - Validate -INFO -print schema done go forward
2023-11-06 10:28:13,669 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-06 10:28:13,671 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-06 10:28:13,671 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-06 10:28:13,671 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-06 10:28:13,671 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-06 10:28:13,671 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-06 10:28:13,671 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-06 10:28:13,672 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-06 10:28:13,672 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-06 10:28:13,672 - Validate -INFO -	StructField(years_of_exp,FloatType,true)
2023-11-06 10:28:13,672 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-06 10:28:13,672 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-06 10:28:13,672 - Validate -INFO -print schema done go forward
2023-11-06 10:28:13,672 - root -INFO -checking for null values in dataframes after procssing...
2023-11-06 10:28:13,673 - Validate -INFO -check for nulls method executing.......for df_fact
2023-11-06 10:32:12,634 - root -INFO -i am in main method...
2023-11-06 10:32:12,635 - Create_spark -INFO -get_spark_object method started...
2023-11-06 10:32:12,635 - Create_spark -INFO -master is local[*]
2023-11-06 10:32:21,183 - root -INFO -Validating spark object.......
2023-11-06 10:32:21,183 - Validate -WARNING -Started get_current_date method ...
2023-11-06 10:32:23,872 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 6))]
2023-11-06 10:32:23,872 - Validate -WARNING -Validation done... go ahead
2023-11-06 10:32:23,872 - root -INFO -reading file which is of > parquet
2023-11-06 10:32:23,873 - Ingest -WARNING -load_files method started
2023-11-06 10:32:24,467 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 10:32:24,468 - root -INFO -displaying file
2023-11-06 10:32:24,468 - root -INFO -here to validate the df
2023-11-06 10:32:24,468 - Ingest -WARNING -here to count the records in the df_city
2023-11-06 10:32:24,983 - Ingest -WARNING -number of records 28338 :: 
2023-11-06 10:32:24,983 - root -INFO -checking for the files in the Fact...
2023-11-06 10:32:24,983 - root -INFO -reading file which is of > csv
2023-11-06 10:32:24,983 - Ingest -WARNING -load_files method started
2023-11-06 10:32:29,174 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 10:32:29,175 - root -INFO -displaying the df_fact dataframe
2023-11-06 10:32:29,175 - Ingest -WARNING -here to count the records in the df_fact
2023-11-06 10:32:29,808 - Ingest -WARNING -number of records 1329329 :: 
2023-11-06 10:32:29,808 - root -INFO -implementing data processing methods....
2023-11-06 10:32:29,808 - Data_processing -WARNING -data_clean method() started...
2023-11-06 10:32:29,808 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-06 10:32:29,847 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-06 10:32:29,869 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-06 10:32:29,919 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-06 10:32:29,945 - Data_processing -WARNING -concat first and lname 
2023-11-06 10:32:29,969 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-06 10:32:29,979 - Data_processing -WARNING -now check for null values in all columns
2023-11-06 10:32:29,979 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-06 10:32:29,995 - Data_processing -WARNING -fill the null values in tx_cnt with the avg value....
2023-11-06 10:32:31,710 - Data_processing -WARNING -successfully dropped the null values....
2023-11-06 10:32:31,711 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-06 10:32:32,425 - root -INFO -validating schema for dataframes...
2023-11-06 10:32:32,425 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-06 10:32:32,426 - Validate -INFO -	StructField(city,StringType,true)
2023-11-06 10:32:32,426 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-06 10:32:32,426 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-06 10:32:32,426 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-06 10:32:32,426 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-06 10:32:32,426 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-06 10:32:32,426 - Validate -INFO -print schema done go forward
2023-11-06 10:32:32,426 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-06 10:32:32,430 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-06 10:32:32,430 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-06 10:32:32,430 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-06 10:32:32,430 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-06 10:32:32,430 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-06 10:32:32,430 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-06 10:32:32,430 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-06 10:32:32,430 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-06 10:32:32,430 - Validate -INFO -	StructField(years_of_exp,FloatType,true)
2023-11-06 10:32:32,430 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-06 10:32:32,430 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-06 10:32:32,430 - Validate -INFO -print schema done go forward
2023-11-06 10:32:32,430 - root -INFO -checking for null values in dataframes after procssing...
2023-11-06 10:32:32,430 - Validate -INFO -check for nulls method executing.......for df_fact
2023-11-06 10:32:32,708 - Validate -WARNING -Check_for_nulls executed successfully...
2023-11-06 10:32:39,085 - root -INFO -Application done...
2023-11-06 10:47:03,978 - root -INFO -i am in main method...
2023-11-06 10:47:03,979 - Create_spark -INFO -get_spark_object method started...
2023-11-06 10:47:03,979 - Create_spark -INFO -master is local[*]
2023-11-06 10:47:14,263 - root -INFO -Validating spark object.......
2023-11-06 10:47:14,264 - Validate -WARNING -Started get_current_date method ...
2023-11-06 10:47:18,203 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 6))]
2023-11-06 10:47:18,203 - Validate -WARNING -Validation done... go ahead
2023-11-06 10:47:18,203 - root -INFO -reading file which is of > parquet
2023-11-06 10:47:18,204 - Ingest -WARNING -load_files method started
2023-11-06 10:47:18,956 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 10:47:18,956 - root -INFO -displaying file
2023-11-06 10:47:18,956 - root -INFO -here to validate the df
2023-11-06 10:47:18,956 - Ingest -WARNING -here to count the records in the df_city
2023-11-06 10:47:19,582 - Ingest -WARNING -number of records 28338 :: 
2023-11-06 10:47:19,582 - root -INFO -checking for the files in the Fact...
2023-11-06 10:47:19,582 - root -INFO -reading file which is of > csv
2023-11-06 10:47:19,582 - Ingest -WARNING -load_files method started
2023-11-06 10:47:24,003 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-06 10:47:24,003 - root -INFO -displaying the df_fact dataframe
2023-11-06 10:47:24,003 - Ingest -WARNING -here to count the records in the df_fact
2023-11-06 10:47:24,667 - Ingest -WARNING -number of records 1329329 :: 
2023-11-06 10:47:24,667 - root -INFO -implementing data processing methods....
2023-11-06 10:47:24,668 - Data_processing -WARNING -data_clean method() started...
2023-11-06 10:47:24,668 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-06 10:47:24,712 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-06 10:47:24,735 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-06 10:47:24,785 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-06 10:47:24,816 - Data_processing -WARNING -concat first and lname 
2023-11-06 10:47:24,838 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-06 10:47:24,847 - Data_processing -WARNING -now check for null values in all columns
2023-11-06 10:47:24,847 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-06 10:47:24,863 - Data_processing -WARNING -fill the null values in tx_cnt with the avg value....
2023-11-06 10:47:26,737 - Data_processing -WARNING -successfully dropped the null values....
2023-11-06 10:47:26,737 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-06 10:47:27,431 - root -INFO -validating schema for dataframes...
2023-11-06 10:47:27,431 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-06 10:47:27,433 - Validate -INFO -	StructField(city,StringType,true)
2023-11-06 10:47:27,433 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-06 10:47:27,433 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-06 10:47:27,434 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-06 10:47:27,434 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-06 10:47:27,434 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-06 10:47:27,434 - Validate -INFO -print schema done go forward
2023-11-06 10:47:27,434 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-06 10:47:27,435 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-06 10:47:27,435 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-06 10:47:27,435 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-06 10:47:27,436 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-06 10:47:27,436 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-06 10:47:27,436 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-06 10:47:27,437 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-06 10:47:27,437 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-06 10:47:27,437 - Validate -INFO -	StructField(years_of_exp,FloatType,true)
2023-11-06 10:47:27,437 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-06 10:47:27,437 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-06 10:47:27,437 - Validate -INFO -print schema done go forward
2023-11-06 10:47:27,437 - root -INFO -checking for null values in dataframes after procssing...
2023-11-06 10:47:27,437 - Validate -INFO -check for nulls method executing.......for df_fact
2023-11-06 10:47:27,693 - Validate -WARNING -Check_for_nulls executed successfully...
2023-11-06 10:47:35,131 - root -INFO -Data transformations executed...
2023-11-06 10:47:35,132 - Data_transformation -WARNING -processing the data_report1 method..
2023-11-06 10:47:35,134 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-06 10:47:35,204 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-11-06 10:47:35,261 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-06 10:47:35,335 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-11-06 10:47:58,484 - root -INFO -Application done...
2023-11-07 10:35:52,857 - root -INFO -i am in main method...
2023-11-07 10:35:52,857 - Create_spark -INFO -get_spark_object method started...
2023-11-07 10:35:52,858 - Create_spark -INFO -master is local[*]
2023-11-07 10:36:21,582 - root -INFO -Validating spark object.......
2023-11-07 10:36:21,582 - Validate -WARNING -Started get_current_date method ...
2023-11-07 10:36:28,604 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 7))]
2023-11-07 10:36:28,604 - Validate -WARNING -Validation done... go ahead
2023-11-07 10:36:28,606 - root -INFO -reading file which is of > parquet
2023-11-07 10:36:28,606 - Ingest -WARNING -load_files method started
2023-11-07 10:36:30,287 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-07 10:36:30,287 - root -INFO -displaying file
2023-11-07 10:36:30,287 - root -INFO -here to validate the df
2023-11-07 10:36:30,287 - Ingest -WARNING -here to count the records in the df_city
2023-11-07 10:36:31,370 - Ingest -WARNING -number of records 28338 :: 
2023-11-07 10:36:31,370 - root -INFO -checking for the files in the Fact...
2023-11-07 10:36:31,371 - root -INFO -reading file which is of > csv
2023-11-07 10:36:31,371 - Ingest -WARNING -load_files method started
2023-11-07 10:36:40,666 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-07 10:36:40,666 - root -INFO -displaying the df_fact dataframe
2023-11-07 10:36:40,666 - Ingest -WARNING -here to count the records in the df_fact
2023-11-07 10:36:41,472 - Ingest -WARNING -number of records 1329329 :: 
2023-11-07 10:36:41,473 - root -INFO -implementing data processing methods....
2023-11-07 10:36:41,473 - Data_processing -WARNING -data_clean method() started...
2023-11-07 10:36:41,473 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-07 10:36:41,551 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-07 10:36:41,580 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-07 10:36:41,640 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-07 10:36:41,683 - Data_processing -WARNING -concat first and lname 
2023-11-07 10:36:41,709 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-07 10:36:41,722 - Data_processing -WARNING -now check for null values in all columns
2023-11-07 10:36:41,722 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-07 10:36:41,740 - Data_processing -WARNING -fill the null values in tx_cnt with the avg value....
2023-11-07 10:36:43,724 - Data_processing -WARNING -successfully dropped the null values....
2023-11-07 10:36:43,724 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-07 10:36:45,391 - root -INFO -validating schema for dataframes...
2023-11-07 10:36:45,391 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-07 10:36:45,393 - Validate -INFO -	StructField(city,StringType,true)
2023-11-07 10:36:45,393 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-07 10:36:45,393 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-07 10:36:45,394 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-07 10:36:45,394 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-07 10:36:45,394 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-07 10:36:45,394 - Validate -INFO -print schema done go forward
2023-11-07 10:36:45,394 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-07 10:36:45,397 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-07 10:36:45,397 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-07 10:36:45,397 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-07 10:36:45,398 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-07 10:36:45,398 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-07 10:36:45,398 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-07 10:36:45,398 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-07 10:36:45,398 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-07 10:36:45,398 - Validate -INFO -	StructField(years_of_exp,FloatType,true)
2023-11-07 10:36:45,398 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-07 10:36:45,398 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-07 10:36:45,398 - Validate -INFO -print schema done go forward
2023-11-07 10:36:45,398 - root -INFO -checking for null values in dataframes after procssing...
2023-11-07 10:36:45,399 - Validate -INFO -check for nulls method executing.......for df_fact
2023-11-07 10:36:45,917 - Validate -WARNING -Check_for_nulls executed successfully...
2023-11-07 10:36:56,117 - root -INFO -Data transformations executed...
2023-11-07 10:36:56,118 - Data_transformation -WARNING -processing the data_report1 method..
2023-11-07 10:36:56,120 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-07 10:36:56,194 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-11-07 10:36:56,271 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-07 10:36:56,341 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-11-07 10:36:56,341 - root -INFO -displaying df_report_1......
2023-11-07 10:37:18,696 - root -INFO -calling data report 2 method...
2023-11-07 10:37:18,696 - Data_transformation -WARNING -executing data_report2 method...
2023-11-07 10:37:18,696 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-07 10:37:18,848 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-11-07 10:37:18,848 - root -INFO -displaying df_report_2......
2023-11-07 10:46:38,773 - root -INFO -i am in main method...
2023-11-07 10:46:38,773 - Create_spark -INFO -get_spark_object method started...
2023-11-07 10:46:38,773 - Create_spark -INFO -master is local[*]
2023-11-07 10:46:48,882 - root -INFO -Validating spark object.......
2023-11-07 10:46:48,882 - Validate -WARNING -Started get_current_date method ...
2023-11-07 10:46:52,751 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 7))]
2023-11-07 10:46:52,751 - Validate -WARNING -Validation done... go ahead
2023-11-07 10:46:52,751 - root -INFO -reading file which is of > parquet
2023-11-07 10:46:52,751 - Ingest -WARNING -load_files method started
2023-11-07 10:46:53,607 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-07 10:46:53,607 - root -INFO -displaying file
2023-11-07 10:46:53,607 - root -INFO -here to validate the df
2023-11-07 10:46:53,607 - Ingest -WARNING -here to count the records in the df_city
2023-11-07 10:46:54,333 - Ingest -WARNING -number of records 28338 :: 
2023-11-07 10:46:54,333 - root -INFO -checking for the files in the Fact...
2023-11-07 10:46:54,334 - root -INFO -reading file which is of > csv
2023-11-07 10:46:54,334 - Ingest -WARNING -load_files method started
2023-11-07 10:46:58,883 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-07 10:46:58,883 - root -INFO -displaying the df_fact dataframe
2023-11-07 10:46:58,883 - Ingest -WARNING -here to count the records in the df_fact
2023-11-07 10:46:59,549 - Ingest -WARNING -number of records 1329329 :: 
2023-11-07 10:46:59,549 - root -INFO -implementing data processing methods....
2023-11-07 10:46:59,549 - Data_processing -WARNING -data_clean method() started...
2023-11-07 10:46:59,549 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-07 10:46:59,604 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-07 10:46:59,635 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-07 10:46:59,722 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-07 10:46:59,767 - Data_processing -WARNING -concat first and lname 
2023-11-07 10:46:59,791 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-07 10:46:59,803 - Data_processing -WARNING -now check for null values in all columns
2023-11-07 10:46:59,803 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-07 10:46:59,821 - Data_processing -WARNING -fill the null values in tx_cnt with the avg value....
2023-11-07 10:47:01,617 - Data_processing -WARNING -successfully dropped the null values....
2023-11-07 10:47:01,617 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-07 10:47:02,671 - root -INFO -validating schema for dataframes...
2023-11-07 10:47:02,671 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-07 10:47:02,674 - Validate -INFO -	StructField(city,StringType,true)
2023-11-07 10:47:02,675 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-07 10:47:02,675 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-07 10:47:02,676 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-07 10:47:02,676 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-07 10:47:02,677 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-07 10:47:02,677 - Validate -INFO -print schema done go forward
2023-11-07 10:47:02,677 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-07 10:47:02,678 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-07 10:47:02,678 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-07 10:47:02,678 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-07 10:47:02,678 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-07 10:47:02,678 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-07 10:47:02,678 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-07 10:47:02,678 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-07 10:47:02,678 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-07 10:47:02,679 - Validate -INFO -	StructField(years_of_exp,FloatType,true)
2023-11-07 10:47:02,679 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-07 10:47:02,679 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-07 10:47:02,679 - Validate -INFO -print schema done go forward
2023-11-07 10:47:02,679 - root -INFO -checking for null values in dataframes after procssing...
2023-11-07 10:47:02,679 - Validate -INFO -check for nulls method executing.......for df_fact
2023-11-07 10:47:03,064 - Validate -WARNING -Check_for_nulls executed successfully...
2023-11-07 10:47:09,633 - root -INFO -Data transformations executed...
2023-11-07 10:47:09,633 - Data_transformation -WARNING -processing the data_report1 method..
2023-11-07 10:47:09,634 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-07 10:47:09,671 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-11-07 10:47:09,704 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-07 10:47:09,749 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-11-07 10:47:09,749 - root -INFO -displaying df_report_1......
2023-11-07 10:47:33,810 - root -INFO -calling data report 2 method...
2023-11-07 10:47:33,812 - Data_transformation -WARNING -executing data_report2 method...
2023-11-07 10:47:33,812 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-07 10:47:34,039 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-11-07 10:47:34,040 - root -INFO -displaying df_report_2......
2023-11-07 10:47:40,355 - root -INFO -Application done...
2023-11-07 10:50:26,691 - root -INFO -i am in main method...
2023-11-07 10:50:26,691 - Create_spark -INFO -get_spark_object method started...
2023-11-07 10:50:26,691 - Create_spark -INFO -master is local[*]
2023-11-07 10:50:36,803 - root -INFO -Validating spark object.......
2023-11-07 10:50:36,803 - Validate -WARNING -Started get_current_date method ...
2023-11-07 10:50:40,917 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 7))]
2023-11-07 10:50:40,917 - Validate -WARNING -Validation done... go ahead
2023-11-07 10:50:40,917 - root -INFO -reading file which is of > parquet
2023-11-07 10:50:40,917 - Ingest -WARNING -load_files method started
2023-11-07 10:50:41,822 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-07 10:50:41,822 - root -INFO -displaying file
2023-11-07 10:50:41,823 - root -INFO -here to validate the df
2023-11-07 10:50:41,823 - Ingest -WARNING -here to count the records in the df_city
2023-11-07 10:50:42,645 - Ingest -WARNING -number of records 28338 :: 
2023-11-07 10:50:42,645 - root -INFO -checking for the files in the Fact...
2023-11-07 10:50:42,645 - root -INFO -reading file which is of > csv
2023-11-07 10:50:42,645 - Ingest -WARNING -load_files method started
2023-11-07 10:50:47,272 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-07 10:50:47,273 - root -INFO -displaying the df_fact dataframe
2023-11-07 10:50:47,273 - Ingest -WARNING -here to count the records in the df_fact
2023-11-07 10:50:47,969 - Ingest -WARNING -number of records 1329329 :: 
2023-11-07 10:50:47,969 - root -INFO -implementing data processing methods....
2023-11-07 10:50:47,969 - Data_processing -WARNING -data_clean method() started...
2023-11-07 10:50:47,969 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-07 10:50:48,021 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-07 10:50:48,049 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-07 10:50:48,133 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-07 10:50:48,182 - Data_processing -WARNING -concat first and lname 
2023-11-07 10:50:48,212 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-07 10:50:48,222 - Data_processing -WARNING -now check for null values in all columns
2023-11-07 10:50:48,222 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-07 10:50:48,242 - Data_processing -WARNING -fill the null values in tx_cnt with the avg value....
2023-11-07 10:50:50,024 - Data_processing -WARNING -successfully dropped the null values....
2023-11-07 10:50:50,024 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-07 10:50:51,108 - root -INFO -validating schema for dataframes...
2023-11-07 10:50:51,108 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-07 10:50:51,110 - Validate -INFO -	StructField(city,StringType,true)
2023-11-07 10:50:51,110 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-07 10:50:51,110 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-07 10:50:51,110 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-07 10:50:51,110 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-07 10:50:51,111 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-07 10:50:51,111 - Validate -INFO -print schema done go forward
2023-11-07 10:50:51,111 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-07 10:50:51,112 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-07 10:50:51,112 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-07 10:50:51,112 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-07 10:50:51,112 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-07 10:50:51,112 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-07 10:50:51,112 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-07 10:50:51,112 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-07 10:50:51,112 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-07 10:50:51,112 - Validate -INFO -	StructField(years_of_exp,FloatType,true)
2023-11-07 10:50:51,113 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-07 10:50:51,113 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-07 10:50:51,113 - Validate -INFO -print schema done go forward
2023-11-07 10:50:51,113 - root -INFO -checking for null values in dataframes after procssing...
2023-11-07 10:50:51,113 - Validate -INFO -check for nulls method executing.......for df_fact
2023-11-07 10:50:51,438 - Validate -WARNING -Check_for_nulls executed successfully...
2023-11-07 10:50:58,150 - root -INFO -Data transformations executed...
2023-11-07 10:50:58,150 - Data_transformation -WARNING -processing the data_report1 method..
2023-11-07 10:50:58,151 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-07 10:50:58,194 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-11-07 10:50:58,224 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-07 10:50:58,264 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-11-07 10:50:58,264 - root -INFO -displaying df_report_1......
2023-11-07 10:51:20,120 - root -INFO -calling data report 2 method...
2023-11-07 10:51:20,120 - Data_transformation -WARNING -executing data_report2 method...
2023-11-07 10:51:20,121 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-07 10:51:20,361 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-11-07 10:51:20,361 - root -INFO -displaying df_report_2......
2023-11-07 10:51:27,406 - root -INFO -Application done...
2023-11-07 10:58:26,845 - root -INFO -i am in main method...
2023-11-07 10:58:26,846 - Create_spark -INFO -get_spark_object method started...
2023-11-07 10:58:26,846 - Create_spark -INFO -master is local[*]
2023-11-07 10:58:36,631 - root -INFO -Validating spark object.......
2023-11-07 10:58:36,631 - Validate -WARNING -Started get_current_date method ...
2023-11-07 10:58:40,535 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 7))]
2023-11-07 10:58:40,535 - Validate -WARNING -Validation done... go ahead
2023-11-07 10:58:40,536 - root -INFO -reading file which is of > parquet
2023-11-07 10:58:40,536 - Ingest -WARNING -load_files method started
2023-11-07 10:58:41,451 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-07 10:58:41,451 - root -INFO -displaying file
2023-11-07 10:58:41,451 - root -INFO -here to validate the df
2023-11-07 10:58:41,451 - Ingest -WARNING -here to count the records in the df_city
2023-11-07 10:58:42,193 - Ingest -WARNING -number of records 28338 :: 
2023-11-07 10:58:42,193 - root -INFO -checking for the files in the Fact...
2023-11-07 10:58:42,194 - root -INFO -reading file which is of > csv
2023-11-07 10:58:42,194 - Ingest -WARNING -load_files method started
2023-11-07 10:58:46,383 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-07 10:58:46,383 - root -INFO -displaying the df_fact dataframe
2023-11-07 10:58:46,384 - Ingest -WARNING -here to count the records in the df_fact
2023-11-07 10:58:47,036 - Ingest -WARNING -number of records 1329329 :: 
2023-11-07 10:58:47,036 - root -INFO -implementing data processing methods....
2023-11-07 10:58:47,037 - Data_processing -WARNING -data_clean method() started...
2023-11-07 10:58:47,037 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-07 10:58:47,094 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-07 10:58:47,119 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-07 10:58:47,188 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-07 10:58:47,240 - Data_processing -WARNING -concat first and lname 
2023-11-07 10:58:47,285 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-07 10:58:47,305 - Data_processing -WARNING -now check for null values in all columns
2023-11-07 10:58:47,305 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-07 10:58:47,334 - Data_processing -WARNING -fill the null values in tx_cnt with the avg value....
2023-11-07 10:58:48,983 - Data_processing -WARNING -successfully dropped the null values....
2023-11-07 10:58:48,983 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-07 10:58:49,971 - root -INFO -validating schema for dataframes...
2023-11-07 10:58:49,972 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-07 10:58:49,973 - Validate -INFO -	StructField(city,StringType,true)
2023-11-07 10:58:49,974 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-07 10:58:49,974 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-07 10:58:49,974 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-07 10:58:49,974 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-07 10:58:49,974 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-07 10:58:49,974 - Validate -INFO -print schema done go forward
2023-11-07 10:58:49,975 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-07 10:58:49,976 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-07 10:58:49,977 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-07 10:58:49,977 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-07 10:58:49,977 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-07 10:58:49,977 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-07 10:58:49,977 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-07 10:58:49,977 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-07 10:58:49,977 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-07 10:58:49,977 - Validate -INFO -	StructField(years_of_exp,FloatType,true)
2023-11-07 10:58:49,978 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-07 10:58:49,978 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-07 10:58:49,978 - Validate -INFO -print schema done go forward
2023-11-07 10:58:49,978 - root -INFO -checking for null values in dataframes after procssing...
2023-11-07 10:58:49,978 - Validate -INFO -check for nulls method executing.......for df_fact
2023-11-07 10:58:50,286 - Validate -WARNING -Check_for_nulls executed successfully...
2023-11-07 10:58:56,609 - root -INFO -Data transformations executed...
2023-11-07 10:58:56,609 - Data_transformation -WARNING -processing the data_report1 method..
2023-11-07 10:58:56,610 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-07 10:58:56,633 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-11-07 10:58:56,661 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-07 10:58:56,711 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-11-07 10:58:56,712 - root -INFO -displaying df_report_1......
2023-11-07 10:59:18,760 - root -INFO -calling data report 2 method...
2023-11-07 10:59:18,761 - Data_transformation -WARNING -executing data_report2 method...
2023-11-07 10:59:18,761 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-07 10:59:19,066 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-11-07 10:59:19,066 - root -INFO -displaying df_report_2......
2023-11-07 10:59:27,247 - root -INFO -extracting df_report_1 to output...
2023-11-07 10:59:27,247 - Extraction -WARNING -extract_files method started executing....
2023-11-07 11:00:03,840 - Extraction -WARNING -extract_file method successfully executed...
2023-11-07 11:00:03,840 - root -INFO -extracting df_report_2 to output...
2023-11-07 11:00:03,840 - Extraction -WARNING -extract_files method started executing....
2023-11-07 11:00:10,929 - Extraction -WARNING -extract_file method successfully executed...
2023-11-07 11:00:10,929 - root -INFO -Application done...
2023-11-30 17:58:19,492 - root -INFO -i am in main method...
2023-11-30 17:58:19,493 - Create_spark -INFO -get_spark_object method started...
2023-11-30 17:58:19,493 - Create_spark -INFO -master is local[*]
2023-11-30 17:58:44,521 - root -INFO -Validating spark object.......
2023-11-30 17:58:44,521 - Validate -WARNING -Started get_current_date method ...
2023-11-30 17:58:48,952 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 30))]
2023-11-30 17:58:48,953 - Validate -WARNING -Validation done... go ahead
2023-11-30 17:58:48,953 - root -INFO -reading file which is of > parquet
2023-11-30 17:58:48,953 - Ingest -WARNING -load_files method started
2023-11-30 17:58:50,056 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-30 17:58:50,056 - root -INFO -displaying file
2023-11-30 17:58:50,057 - root -INFO -here to validate the df
2023-11-30 17:58:50,057 - Ingest -WARNING -here to count the records in the df_city
2023-11-30 17:58:50,730 - Ingest -WARNING -number of records 28338 :: 
2023-11-30 17:58:50,730 - root -INFO -checking for the files in the Fact...
2023-11-30 17:58:50,730 - root -INFO -reading file which is of > csv
2023-11-30 17:58:50,730 - Ingest -WARNING -load_files method started
2023-11-30 17:58:53,969 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-30 17:58:53,970 - root -INFO -displaying the df_fact dataframe
2023-11-30 17:58:53,970 - Ingest -WARNING -here to count the records in the df_fact
2023-11-30 17:58:55,142 - Ingest -WARNING -number of records 286090 :: 
2023-11-30 17:58:55,143 - root -INFO -implementing data processing methods....
2023-11-30 17:58:55,143 - Data_processing -WARNING -data_clean method() started...
2023-11-30 17:58:55,143 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-30 17:58:55,228 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-30 18:08:33,146 - root -INFO -i am in main method...
2023-11-30 18:08:33,147 - Create_spark -INFO -get_spark_object method started...
2023-11-30 18:08:33,147 - Create_spark -INFO -master is local[*]
2023-11-30 18:08:41,980 - root -INFO -Validating spark object.......
2023-11-30 18:08:41,981 - Validate -WARNING -Started get_current_date method ...
2023-11-30 18:08:44,612 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 30))]
2023-11-30 18:08:44,613 - Validate -WARNING -Validation done... go ahead
2023-11-30 18:08:44,613 - root -INFO -reading file which is of > parquet
2023-11-30 18:08:44,613 - Ingest -WARNING -load_files method started
2023-11-30 18:08:45,211 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-30 18:08:45,211 - root -INFO -displaying file
2023-11-30 18:08:46,389 - root -INFO -here to validate the df
2023-11-30 18:08:46,406 - Ingest -WARNING -here to count the records in the df_city
2023-11-30 18:08:46,824 - Ingest -WARNING -number of records 28338 :: 
2023-11-30 18:08:46,824 - root -INFO -checking for the files in the Fact...
2023-11-30 18:08:46,824 - root -INFO -reading file which is of > csv
2023-11-30 18:08:46,824 - Ingest -WARNING -load_files method started
2023-11-30 18:08:49,774 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-30 18:08:49,774 - root -INFO -displaying the df_fact dataframe
2023-11-30 18:08:50,041 - Ingest -WARNING -here to count the records in the df_fact
2023-11-30 18:08:50,984 - Ingest -WARNING -number of records 286090 :: 
2023-11-30 18:08:50,984 - root -INFO -implementing data processing methods....
2023-11-30 18:08:50,984 - root -INFO -Application done...
2023-11-30 18:09:13,984 - root -INFO -i am in main method...
2023-11-30 18:09:13,984 - Create_spark -INFO -get_spark_object method started...
2023-11-30 18:09:13,984 - Create_spark -INFO -master is local[*]
2023-11-30 18:09:22,739 - root -INFO -Validating spark object.......
2023-11-30 18:09:22,739 - Validate -WARNING -Started get_current_date method ...
2023-11-30 18:09:25,486 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 30))]
2023-11-30 18:09:25,486 - Validate -WARNING -Validation done... go ahead
2023-11-30 18:09:25,486 - root -INFO -reading file which is of > parquet
2023-11-30 18:09:25,487 - Ingest -WARNING -load_files method started
2023-11-30 18:09:26,063 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-30 18:09:26,063 - root -INFO -displaying file
2023-11-30 18:09:26,940 - root -INFO -here to validate the df
2023-11-30 18:09:26,940 - Ingest -WARNING -here to count the records in the df_city
2023-11-30 18:09:27,346 - Ingest -WARNING -number of records 28338 :: 
2023-11-30 18:09:27,346 - root -INFO -checking for the files in the Fact...
2023-11-30 18:09:27,346 - root -INFO -reading file which is of > csv
2023-11-30 18:09:27,347 - Ingest -WARNING -load_files method started
2023-11-30 18:09:31,677 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-30 18:09:31,677 - root -INFO -displaying the df_fact dataframe
2023-11-30 18:09:31,996 - Ingest -WARNING -here to count the records in the df_fact
2023-11-30 18:09:32,646 - Ingest -WARNING -number of records 1329329 :: 
2023-11-30 18:09:32,647 - root -INFO -implementing data processing methods....
2023-11-30 18:09:32,647 - root -INFO -Application done...
2023-11-30 18:11:25,394 - root -INFO -i am in main method...
2023-11-30 18:11:25,395 - Create_spark -INFO -get_spark_object method started...
2023-11-30 18:11:25,395 - Create_spark -INFO -master is local[*]
2023-11-30 18:11:34,019 - root -INFO -Validating spark object.......
2023-11-30 18:11:34,019 - Validate -WARNING -Started get_current_date method ...
2023-11-30 18:11:36,695 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 30))]
2023-11-30 18:11:36,695 - Validate -WARNING -Validation done... go ahead
2023-11-30 18:11:36,695 - root -INFO -reading file which is of > parquet
2023-11-30 18:11:36,695 - Ingest -WARNING -load_files method started
2023-11-30 18:11:37,335 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-30 18:11:37,335 - root -INFO -displaying file
2023-11-30 18:11:37,335 - root -INFO -here to validate the df
2023-11-30 18:11:37,335 - Ingest -WARNING -here to count the records in the df_city
2023-11-30 18:11:37,843 - Ingest -WARNING -number of records 28338 :: 
2023-11-30 18:11:37,843 - root -INFO -checking for the files in the Fact...
2023-11-30 18:11:37,844 - root -INFO -reading file which is of > csv
2023-11-30 18:11:37,844 - Ingest -WARNING -load_files method started
2023-11-30 18:11:41,944 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-30 18:11:41,945 - root -INFO -displaying the df_fact dataframe
2023-11-30 18:11:41,945 - Ingest -WARNING -here to count the records in the df_fact
2023-11-30 18:11:42,549 - Ingest -WARNING -number of records 1329329 :: 
2023-11-30 18:11:42,549 - root -INFO -implementing data processing methods....
2023-11-30 18:11:42,549 - Data_processing -WARNING -data_clean method() started...
2023-11-30 18:11:42,549 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-30 18:11:42,592 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-30 18:11:42,613 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-30 18:11:42,665 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-30 18:11:42,696 - Data_processing -WARNING -concat first and lname 
2023-11-30 18:11:42,720 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-30 18:11:42,729 - Data_processing -WARNING -now check for null values in all columns
2023-11-30 18:11:42,729 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-30 18:11:42,748 - Data_processing -WARNING -fill the null values in tx_cnt with the avg value....
2023-11-30 18:11:44,438 - Data_processing -WARNING -successfully dropped the null values....
2023-11-30 18:11:44,438 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-30 18:11:45,138 - root -INFO -validating schema for dataframes...
2023-11-30 18:11:45,138 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-30 18:11:45,139 - Validate -INFO -	StructField(city,StringType,true)
2023-11-30 18:11:45,139 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-30 18:11:45,139 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-30 18:11:45,140 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-30 18:11:45,140 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-30 18:11:45,140 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-30 18:11:45,140 - Validate -INFO -print schema done go forward
2023-11-30 18:11:45,140 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-30 18:11:45,141 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-30 18:11:45,142 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-30 18:11:45,142 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-30 18:11:45,142 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-30 18:11:45,142 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-30 18:11:45,142 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-30 18:11:45,142 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-30 18:11:45,142 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-30 18:11:45,142 - Validate -INFO -	StructField(years_of_exp,FloatType,true)
2023-11-30 18:11:45,142 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-30 18:11:45,143 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-30 18:11:45,143 - Validate -INFO -print schema done go forward
2023-11-30 18:11:45,143 - root -INFO -checking for null values in dataframes after procssing...
2023-11-30 18:11:45,143 - Validate -INFO -check for nulls method executing.......for df_fact
2023-11-30 18:11:45,489 - Validate -WARNING -Check_for_nulls executed successfully...
2023-11-30 18:11:52,257 - root -INFO -Data transformations executed...
2023-11-30 18:11:52,258 - Data_transformation -WARNING -processing the data_report1 method..
2023-11-30 18:11:52,258 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-30 18:11:52,300 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-11-30 18:11:52,322 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-30 18:11:52,357 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-11-30 18:11:52,357 - root -INFO -displaying df_report_1......
2023-11-30 18:12:10,462 - root -INFO -calling data report 2 method...
2023-11-30 18:12:10,463 - Data_transformation -WARNING -executing data_report2 method...
2023-11-30 18:12:10,463 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-30 18:12:10,653 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-11-30 18:12:10,654 - root -INFO -displaying df_report_2......
2023-11-30 18:12:16,329 - root -INFO -extracting df_report_1 to output...
2023-11-30 18:12:16,329 - Extraction -WARNING -extract_files method started executing....
2023-11-30 18:12:45,355 - Extraction -WARNING -extract_file method successfully executed...
2023-11-30 18:12:45,355 - root -INFO -extracting df_report_2 to output...
2023-11-30 18:12:45,356 - Extraction -WARNING -extract_files method started executing....
2023-11-30 18:12:51,591 - Extraction -WARNING -extract_file method successfully executed...
2023-11-30 18:12:51,591 - root -INFO -extracting files completed...
2023-11-30 18:12:51,591 - root -INFO -writing into hive table started...
2023-11-30 18:12:51,591 - Persist -WARNING -persisting the data into Hive Table for df_city
2023-11-30 18:12:51,591 - Persist -WARNING -lets create a database....
2023-11-30 18:13:13,589 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into hive_table by state_name 
2023-11-30 18:16:55,007 - Persist -WARNING -Data successfully persisted into hive tables...
2023-11-30 18:16:55,007 - Persist -WARNING -persisting the data into Hive Table for df_presc
2023-11-30 18:16:55,007 - Persist -WARNING -lets create a database....
2023-11-30 18:16:55,071 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: float, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into hive_table by presc_state 
2023-11-30 18:17:10,035 - Persist -WARNING -Data successfully persisted into hive tables...
2023-11-30 18:17:10,035 - root -INFO -writing into hive table completed...
2023-11-30 18:17:10,035 - root -INFO -Application done...
2023-11-30 18:34:02,546 - root -INFO -i am in main method...
2023-11-30 18:34:02,546 - Create_spark -INFO -get_spark_object method started...
2023-11-30 18:34:02,546 - Create_spark -INFO -master is local[*]
2023-11-30 18:34:11,461 - root -INFO -Validating spark object.......
2023-11-30 18:34:11,462 - Validate -WARNING -Started get_current_date method ...
2023-11-30 18:34:14,089 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 11, 30))]
2023-11-30 18:34:14,089 - Validate -WARNING -Validation done... go ahead
2023-11-30 18:34:14,089 - root -INFO -reading file which is of > parquet
2023-11-30 18:34:14,090 - Ingest -WARNING -load_files method started
2023-11-30 18:34:14,702 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-30 18:34:14,702 - root -INFO -displaying file
2023-11-30 18:34:14,702 - root -INFO -here to validate the df
2023-11-30 18:34:14,703 - Ingest -WARNING -here to count the records in the df_city
2023-11-30 18:34:15,223 - Ingest -WARNING -number of records 28338 :: 
2023-11-30 18:34:15,224 - root -INFO -checking for the files in the Fact...
2023-11-30 18:34:15,224 - root -INFO -reading file which is of > csv
2023-11-30 18:34:15,224 - Ingest -WARNING -load_files method started
2023-11-30 18:34:19,343 - Ingest -WARNING -Load_files func done, go fwd..
2023-11-30 18:34:19,343 - root -INFO -displaying the df_fact dataframe
2023-11-30 18:34:19,344 - Ingest -WARNING -here to count the records in the df_fact
2023-11-30 18:34:19,981 - Ingest -WARNING -number of records 1329329 :: 
2023-11-30 18:34:19,981 - root -INFO -implementing data processing methods....
2023-11-30 18:34:19,981 - Data_processing -WARNING -data_clean method() started...
2023-11-30 18:34:19,982 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-11-30 18:34:20,024 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-11-30 18:34:20,050 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-11-30 18:34:20,097 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-11-30 18:34:20,126 - Data_processing -WARNING -concat first and lname 
2023-11-30 18:34:20,148 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-11-30 18:34:20,156 - Data_processing -WARNING -now check for null values in all columns
2023-11-30 18:34:20,156 - Data_processing -WARNING -drop the null values in the respective columns....
2023-11-30 18:34:20,171 - Data_processing -WARNING -fill the null values in tx_cnt with the avg value....
2023-11-30 18:34:21,896 - Data_processing -WARNING -successfully dropped the null values....
2023-11-30 18:34:21,896 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-11-30 18:34:22,673 - root -INFO -validating schema for dataframes...
2023-11-30 18:34:22,673 - Validate -WARNING -print schema method executing...df_city_sel
2023-11-30 18:34:22,675 - Validate -INFO -	StructField(city,StringType,true)
2023-11-30 18:34:22,675 - Validate -INFO -	StructField(state_id,StringType,true)
2023-11-30 18:34:22,676 - Validate -INFO -	StructField(state_name,StringType,true)
2023-11-30 18:34:22,676 - Validate -INFO -	StructField(county_name,StringType,true)
2023-11-30 18:34:22,676 - Validate -INFO -	StructField(population,IntegerType,true)
2023-11-30 18:34:22,676 - Validate -INFO -	StructField(zips,StringType,true)
2023-11-30 18:34:22,676 - Validate -INFO -print schema done go forward
2023-11-30 18:34:22,676 - Validate -WARNING -print schema method executing...df_presc_sel
2023-11-30 18:34:22,678 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-11-30 18:34:22,678 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-11-30 18:34:22,678 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-11-30 18:34:22,679 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-11-30 18:34:22,679 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-11-30 18:34:22,679 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-11-30 18:34:22,679 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-11-30 18:34:22,679 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-11-30 18:34:22,679 - Validate -INFO -	StructField(years_of_exp,FloatType,true)
2023-11-30 18:34:22,679 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-11-30 18:34:22,679 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-11-30 18:34:22,679 - Validate -INFO -print schema done go forward
2023-11-30 18:34:22,680 - root -INFO -checking for null values in dataframes after procssing...
2023-11-30 18:34:22,680 - Validate -INFO -check for nulls method executing.......for df_fact
2023-11-30 18:34:22,987 - Validate -WARNING -Check_for_nulls executed successfully...
2023-11-30 18:34:30,058 - root -INFO -Data transformations executed...
2023-11-30 18:34:30,058 - Data_transformation -WARNING -processing the data_report1 method..
2023-11-30 18:34:30,059 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-30 18:34:30,086 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-11-30 18:34:30,108 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-30 18:34:30,138 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-11-30 18:34:30,138 - root -INFO -displaying df_report_1......
2023-11-30 18:34:48,942 - root -INFO -calling data report 2 method...
2023-11-30 18:34:48,942 - Data_transformation -WARNING -executing data_report2 method...
2023-11-30 18:34:48,942 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-30 18:34:49,163 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-11-30 18:34:49,163 - root -INFO -displaying df_report_2......
2023-11-30 18:34:54,838 - root -INFO -extracting df_report_1 to output...
2023-11-30 18:34:54,838 - Extraction -WARNING -extract_files method started executing....
2023-11-30 18:35:24,060 - Extraction -WARNING -extract_file method successfully executed...
2023-11-30 18:35:24,060 - root -INFO -extracting df_report_2 to output...
2023-11-30 18:35:24,060 - Extraction -WARNING -extract_files method started executing....
2023-11-30 18:35:30,047 - Extraction -WARNING -extract_file method successfully executed...
2023-11-30 18:35:30,047 - root -INFO -extracting files completed...
2023-11-30 18:35:30,047 - root -INFO -writing into hive table started...
2023-11-30 18:35:30,048 - Persist -WARNING -persisting the data into Hive Table for df_city
2023-11-30 18:35:30,048 - Persist -WARNING -lets create a database....
2023-11-30 18:35:48,531 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into hive_table by state_name 
2023-11-30 18:39:38,622 - Persist -WARNING -Data successfully persisted into hive tables...
2023-11-30 18:39:38,622 - Persist -WARNING -persisting the data into Hive Table for df_presc
2023-11-30 18:39:38,622 - Persist -WARNING -lets create a database....
2023-11-30 18:39:38,716 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: float, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into hive_table by presc_state 
2023-11-30 18:39:57,698 - Persist -WARNING -Data successfully persisted into hive tables...
2023-11-30 18:39:57,699 - root -INFO -writing into hive table completed...
2023-11-30 18:39:57,699 - root -INFO -Application done...
2023-12-01 10:18:14,023 - root -INFO -i am in main method...
2023-12-01 10:18:14,023 - Create_spark -INFO -get_spark_object method started...
2023-12-01 10:18:14,023 - Create_spark -INFO -master is local[*]
2023-12-01 10:18:39,623 - root -INFO -Validating spark object.......
2023-12-01 10:18:39,624 - Validate -WARNING -Started get_current_date method ...
2023-12-01 10:18:43,633 - Validate -WARNING -validating spark object with current date : [Row(current_date()=datetime.date(2023, 12, 1))]
2023-12-01 10:18:43,633 - Validate -WARNING -Validation done... go ahead
2023-12-01 10:18:43,633 - root -INFO -reading file which is of > parquet
2023-12-01 10:18:43,633 - Ingest -WARNING -load_files method started
2023-12-01 10:18:44,874 - Ingest -WARNING -Load_files func done, go fwd..
2023-12-01 10:18:44,874 - root -INFO -displaying file
2023-12-01 10:18:44,874 - root -INFO -here to validate the df
2023-12-01 10:18:44,875 - Ingest -WARNING -here to count the records in the df_city
2023-12-01 10:18:46,223 - Ingest -WARNING -number of records 28338 :: 
2023-12-01 10:18:46,223 - root -INFO -checking for the files in the Fact...
2023-12-01 10:18:46,224 - root -INFO -reading file which is of > csv
2023-12-01 10:18:46,224 - Ingest -WARNING -load_files method started
2023-12-01 10:18:55,674 - Ingest -WARNING -Load_files func done, go fwd..
2023-12-01 10:18:55,675 - root -INFO -displaying the df_fact dataframe
2023-12-01 10:18:55,675 - Ingest -WARNING -here to count the records in the df_fact
2023-12-01 10:18:56,860 - Ingest -WARNING -number of records 1329329 :: 
2023-12-01 10:18:56,860 - root -INFO -implementing data processing methods....
2023-12-01 10:18:56,860 - Data_processing -WARNING -data_clean method() started...
2023-12-01 10:18:56,860 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-12-01 10:18:56,907 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-12-01 10:18:56,931 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-12-01 10:18:56,977 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-12-01 10:18:57,008 - Data_processing -WARNING -concat first and lname 
2023-12-01 10:18:57,026 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-12-01 10:18:57,036 - Data_processing -WARNING -now check for null values in all columns
2023-12-01 10:18:57,036 - Data_processing -WARNING -drop the null values in the respective columns....
2023-12-01 10:18:57,052 - Data_processing -WARNING -fill the null values in tx_cnt with the avg value....
2023-12-01 10:18:59,006 - Data_processing -WARNING -successfully dropped the null values....
2023-12-01 10:18:59,006 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-12-01 10:18:59,916 - root -INFO -validating schema for dataframes...
2023-12-01 10:18:59,916 - Validate -WARNING -print schema method executing...df_city_sel
2023-12-01 10:18:59,917 - Validate -INFO -	StructField(city,StringType,true)
2023-12-01 10:18:59,917 - Validate -INFO -	StructField(state_id,StringType,true)
2023-12-01 10:18:59,917 - Validate -INFO -	StructField(state_name,StringType,true)
2023-12-01 10:18:59,918 - Validate -INFO -	StructField(county_name,StringType,true)
2023-12-01 10:18:59,918 - Validate -INFO -	StructField(population,IntegerType,true)
2023-12-01 10:18:59,918 - Validate -INFO -	StructField(zips,StringType,true)
2023-12-01 10:18:59,918 - Validate -INFO -print schema done go forward
2023-12-01 10:18:59,918 - Validate -WARNING -print schema method executing...df_presc_sel
2023-12-01 10:18:59,921 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-12-01 10:18:59,921 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-12-01 10:18:59,921 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-12-01 10:18:59,921 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-12-01 10:18:59,921 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-12-01 10:18:59,921 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-12-01 10:18:59,921 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-12-01 10:18:59,921 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-12-01 10:18:59,921 - Validate -INFO -	StructField(years_of_exp,FloatType,true)
2023-12-01 10:18:59,922 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-12-01 10:18:59,923 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-12-01 10:18:59,923 - Validate -INFO -print schema done go forward
2023-12-01 10:18:59,923 - root -INFO -checking for null values in dataframes after procssing...
2023-12-01 10:18:59,923 - Validate -INFO -check for nulls method executing.......for df_fact
2023-12-01 10:19:00,242 - Validate -WARNING -Check_for_nulls executed successfully...
2023-12-01 10:19:08,279 - root -INFO -Data transformations executed...
2023-12-01 10:19:08,280 - Data_transformation -WARNING -processing the data_report1 method..
2023-12-01 10:19:08,280 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-12-01 10:19:08,359 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-12-01 10:19:08,389 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-12-01 10:19:08,435 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-12-01 10:19:08,435 - root -INFO -displaying df_report_1......
2023-12-01 10:19:30,600 - root -INFO -calling data report 2 method...
2023-12-01 10:19:30,600 - Data_transformation -WARNING -executing data_report2 method...
2023-12-01 10:19:30,600 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-12-01 10:19:30,859 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-12-01 10:19:30,859 - root -INFO -displaying df_report_2......
2023-12-01 10:19:38,429 - root -INFO -extracting df_report_1 to output...
2023-12-01 10:19:38,429 - Extraction -WARNING -extract_files method started executing....
2023-12-01 10:20:11,946 - Extraction -WARNING -extract_file method successfully executed...
2023-12-01 10:20:11,946 - root -INFO -extracting df_report_2 to output...
2023-12-01 10:20:11,946 - Extraction -WARNING -extract_files method started executing....
2023-12-01 10:20:18,450 - Extraction -WARNING -extract_file method successfully executed...
2023-12-01 10:20:18,451 - root -INFO -extracting files completed...
2023-12-01 10:20:18,451 - root -INFO -writing into hive table started...
2023-12-01 10:20:18,451 - Persist -WARNING -persisting the data into Hive Table for df_city
2023-12-01 10:20:18,451 - Persist -WARNING -lets create a database....
2023-12-01 10:20:35,523 - Persist -WARNING -Now writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into hive_table by state_name 
2023-12-01 10:24:48,992 - Persist -WARNING -Data successfully persisted into hive tables...
2023-12-01 10:24:48,993 - Persist -WARNING -persisting the data into Hive Table for df_presc
2023-12-01 10:24:48,993 - Persist -WARNING -lets create a database....
2023-12-01 10:24:49,022 - Persist -WARNING -Now writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: float, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into hive_table by presc_state 
2023-12-01 10:25:09,738 - Persist -WARNING -Data successfully persisted into hive tables...
2023-12-01 10:25:09,738 - root -INFO -successfully written into hive...
2023-12-01 10:25:09,740 - root -INFO -Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into mysql...
2023-12-01 10:25:09,740 - Persist -WARNING -executing the data_persist_mysql method...df_city
